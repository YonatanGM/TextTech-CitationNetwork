<paper id="1549658602"><title>Dual Strategy Active Learning</title><year>2007</year><authors><author org="School of Computer Science, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh PA, 15213, USA#TAB#" id="1264356972">Pinar Donmez</author><author org="School of Computer Science, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh PA, 15213, USA#TAB#" id="2100444261">Jaime G. Carbonell</author><author org="Microsoft Research, 1 Microsoft Way, Redmond, WA 98052, USA#TAB#" id="2137013502">Paul N. Bennett</author></authors><n_citation>125</n_citation><doc_type>Conference</doc_type><references><reference>120286951</reference><reference>1484084878</reference><reference>1514707997</reference><reference>1514940655</reference><reference>1515450954</reference><reference>1528361845</reference><reference>1540007258</reference><reference>1599935123</reference><reference>1666672054</reference><reference>1942925359</reference><reference>1978633512</reference><reference>2009207944</reference><reference>2077902449</reference><reference>2080021732</reference><reference>2085989833</reference><reference>2098203240</reference><reference>2134473739</reference><reference>2426031434</reference><reference>2569915378</reference></references><venue id="2755314191" type="C">European conference on Machine Learning</venue><doi>10.1007/978-3-540-74958-5_14</doi><keywords><keyword weight="0.51021">Density estimation</keyword><keyword weight="0.525">Residual</keyword><keyword weight="0.52151">Diffusing update algorithm</keyword><keyword weight="0.52285">Active learning</keyword><keyword weight="0.44125">Computer science</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.54216">Sampling (statistics)</keyword><keyword weight="0.467">Machine learning</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>Active Learning methods rely on static strategies for sampling unlabeled point(s). These strategies range from uncertainty sampling and density estimation to multi-factor methods with learn-once-use-always model parameters. This paper proposes a dynamic approach, called DUAL, where the strategy selection parameters are adaptively updated based on estimated future residual error reduction after each actively sampled point. The objective of dual is to outperform static strategies over a large operating range: from very few to very many labeled points. Empirical results over six datasets demonstrate that DUAL outperforms several state-of-the-art methods on most datasets.</abstract></paper>