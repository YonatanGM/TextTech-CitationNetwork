<paper id="1533419692"><title>Relative Building-Block Fitness and the Building-Block Hypothesis</title><year>1993</year><authors><author org="Department of Computer Science, University of New Mexico, Albuquerque, NM" id="2159603389">Stephanie Forrest</author><author org="AI Laboratory University of Michigan Ann Arbor, MI 48109" id="2160125451">Melanie Mitchell</author></authors><n_citation>310</n_citation><doc_type>Conference</doc_type><references><reference>2372683</reference><reference>42654547</reference><reference>64312882</reference><reference>64702643</reference><reference>77512158</reference><reference>139356917</reference><reference>141541527</reference><reference>161518142</reference><reference>1496027058</reference><reference>1499561572</reference><reference>1566803874</reference><reference>1639032689</reference><reference>1787544972</reference><reference>1967093065</reference><reference>2009157513</reference><reference>2163528881</reference></references><venue id="1159491267" type="C">Foundations of Genetic Algorithms</venue><doi>10.1016/B978-0-08-094832-4.50013-1</doi><keywords><keyword weight="0.48482">Open problem</keyword><keyword weight="0.57856">Fitness landscape</keyword><keyword weight="0.55072">Crossover</keyword><keyword weight="0.45038">Computer science</keyword><keyword weight="0.46412">Artificial intelligence</keyword><keyword weight="0.47322">Operator (computer programming)</keyword><keyword weight="0.45069">Schema (psychology)</keyword><keyword weight="0.45504">Machine learning</keyword></keywords><publisher>Elsevier</publisher><abstract>Abstract The building-block hypothesis states that the GA works well when short, low-order, highly-fit schemas recombine to form even more highly fit higher-order schemas. The ability to produce fitter and fitter partial solutions by combining building blocks is believed to be a primary source of the GAu0027s search power, but the GA research community currently lacks precise and quantitative descriptions of how schema processing actually takes place during the typical evolution of a GA search. Another open problem is to characterize in detail the types of fitness landscapes for which crossover will be an effective operator. In this paper we first describe a class of fitness landscapes (the “Royal Road” functions) that we have designed to investigate these questions. We then present some unexpected experimental results concerning the GAu0027s performance on simple instances of these landscapes, in which we vary the strength of reinforcement from “stepping stones”—fit intermediate-order schemas obtained by recombining fit low-order schemas. Finally, we compare the performance of the GA on these functions with that of three commonly used hill-climbing schemes, and find that one of them, “random-mutation hill-climbing”, significantly outperforms the GA on these functions.</abstract></paper>