<paper id="1484422715"><title>How to Make Replicated Data Secure</title><year>1987</year><authors><author org="Carnegie - Mellon University#TAB#" id="2068258939">Maurice Herlihy</author><author org="Carnegie - Mellon University#TAB#" id="2237110490">J. D. Tygar</author></authors><n_citation>81</n_citation><doc_type>Conference</doc_type><references><reference>34896621</reference><reference>88281988</reference><reference>1607773857</reference><reference>1972418517</reference><reference>1973501242</reference><reference>1996360405</reference><reference>2012848290</reference><reference>2018562795</reference><reference>2043944888</reference><reference>2064627910</reference><reference>2108104892</reference><reference>2142849519</reference><reference>2146973388</reference><reference>2156186849</reference><reference>2163684994</reference></references><venue id="1153524033" type="C">International Cryptology Conference</venue><doi>10.1007/3-540-48184-2_33</doi><keywords><keyword weight="0.51151">Secret sharing</keyword><keyword weight="0.46765">Computer security</keyword><keyword weight="0.46259">Computer science</keyword><keyword weight="0.52098">Adversary</keyword><keyword weight="0.0">Data objects</keyword><keyword weight="0.4994">Data Protection Act 1998</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>Many distributed systems manage some form of long-lived data, such as files or data bases. The performance and fault-tolerance of such systems may be enhanced if the repositories for the data are physically distributed. Nevertheless, distribution makes security more difficult, since it may be difficult to ensure that each repository is physically secure, particularly if the number of repositories is large. This paper proposes new techniques for ensuring the security of long-lived, physically distributed data. These techniques adapt replication protocols for fault-tolerance to the more demanding requirements of security. For a given threshold value, one set of protocols ensures that an adversary cannot ascertain the state of a data object by observing the contents of fewer than a threshold of repositories. These protocols are cheap; the message traffic needed to tolerate a given number of compromised repositories is only slightly more than the message traffic needed to tolerate the same number of failures. A second set of protocols ensures that an objectu0027s state cannot be altered by an adversary who can modify the contents of fewer than a threshold of repositories. These protocols are more expensive; to tolerate t-1 compromised repositories, clients executing certain operations must communicate with t-1 additional sites.</abstract></paper>