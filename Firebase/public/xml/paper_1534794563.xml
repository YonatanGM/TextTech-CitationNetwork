<paper id="1534794563"><title>FRATS: A parallel reduction strategy for shared memory</title><year>1991</year><authors><author org="University of Amsterdam" id="1969311846">Koen Langendoen</author><author org="University of Amsterdam" id="1968545134">Willem G. Vree</author></authors><n_citation>5</n_citation><doc_type>Conference</doc_type><references><reference>1577503839</reference><reference>1990067258</reference><reference>2048867801</reference><reference>2063068243</reference><reference>2085014646</reference><reference>2087090231</reference><reference>2122250035</reference><reference>2132084888</reference><reference>2136608835</reference></references><venue id="2754504537" type="C">International Symposium on Programming Language Implementation and Logic Programming</venue><doi>10.1007/3-540-54444-5_91</doi><keywords><keyword weight="0.55423">Uniform memory access</keyword><keyword weight="0.55314">Shared memory</keyword><keyword weight="0.55942">Eager evaluation</keyword><keyword weight="0.45821">Computer science</keyword><keyword weight="0.46388">Parallel computing</keyword><keyword weight="0.56293">Distributed memory</keyword><keyword weight="0.53797">Data diffusion machine</keyword><keyword weight="0.51909">Memory management</keyword><keyword weight="0.57942">Distributed shared memory</keyword><keyword weight="0.55507">Shared disk architecture</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>FRATS is a strategy for parallel execution of functional languages on shared memory multiprocessors. It provides fork-join parallelism through the explicit us-age of an annotation to (recursively) spark a set of parallel tasks. These tasks are executed by ordinary sequential graph reducers which share the program graph. FRATS avoids the consistency problem of graph reducers updating shared nodes by a special evaluation order: Before sparking a set of tasks, all (sub) redexes in those tasks are reduced to normal forms. Then the tasks can proceed in parallel without any synchronisation (e.g., locks) because tasks only share normalised graph nodes. The eager evaluation of shared redexes, however, does not preserve full laziness which might result in superfluous or, worse, infinite computation. The paper presents in detail program transformations to enforce termination and avoid superfluous computation. Analysis of a benchmark of parallel applications shows that these transformations are necessary and effective with negligible costs. Sometimes they even increase performance.</abstract></paper>