<paper id="1502112145"><title>Tiered Tagging and Combined Language Models Classifiers</title><year>1999</year><authors><author org="RACAI-Romanian Academy" id="39990776">Dan Tufis</author></authors><n_citation>43</n_citation><doc_type>Conference</doc_type><references><reference>1496929357</reference><reference>1857972659</reference><reference>2130636661</reference><reference>2167277498</reference><reference>2249186037</reference></references><venue id="1142381819" type="C">Text, Speech and Dialogue</venue><doi>10.1007/3-540-48239-3_5</doi><keywords><keyword weight="0.44069">Computer science</keyword><keyword weight="0.45971">Speech recognition</keyword><keyword weight="0.56826">Natural language</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.48061">Natural language processing</keyword><keyword weight="0.48862">Classifier (linguistics)</keyword><keyword weight="0.4549">Possessive</keyword><keyword weight="0.62382">Language model</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>We address the problem of morpho-syntactic disambiguation of arbitrary texts in a highly inflectional natural language. We use a large tagset (615 tags), EAGLES and MULTEXT compliant [5]. The large tagset is internally mapped onto a reduced one (82 tags), serving statistical disambiguation, and a text disambiguated in terms of this tagset is subsequently subject to a recovery process of all the information left out from the large tagset. This two step process is called tiered tagging. To further improve the tagging accuracy we use a combined language models classifier, a procedure that interpolates the results of tagging the same text with several register-specific language models.</abstract></paper>