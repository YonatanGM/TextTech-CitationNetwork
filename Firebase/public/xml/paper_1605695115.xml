<paper id="1605695115"><title>Learning When Negative Examples Abound</title><year>1997</year><authors><author org="Department of Computer Science, University of Ottawa, Ottawa, Canada#TAB#" id="2491843800">Miroslav Kubat</author><author org="Department of Computer Science, University of Ottawa, Ottawa, Canada#TAB#" id="2000740313">Robert Holte</author><author org="Department of Computer Science, University of Ottawa, Ottawa, Canada#TAB#" id="2195580174">Stan Matwin</author></authors><n_citation>198</n_citation><doc_type>Conference</doc_type><references><reference>1493526108</reference><reference>1510806966</reference><reference>1513874326</reference><reference>1515620500</reference><reference>1520046401</reference><reference>1595468493</reference><reference>1696243063</reference><reference>1988790447</reference><reference>2062689875</reference><reference>2075038844</reference><reference>2125055259</reference><reference>2146935111</reference></references><venue id="2755314191" type="C">European conference on Machine Learning</venue><doi>10.1007/3-540-62858-4_79</doi><keywords><keyword weight="0.66117">Stability (learning theory)</keyword><keyword weight="0.66088">Active learning (machine learning)</keyword><keyword weight="0.46543">Computer science</keyword><keyword weight="0.5821">Concept learning</keyword><keyword weight="0.47121">Artificial intelligence</keyword><keyword weight="0.47082">Machine learning</keyword><keyword weight="0.41721">Binary number</keyword></keywords><publisher>Springer-Verlag</publisher><abstract>Existing concept learning systems can fail when the negative examples heavily outnumber the positive examples. The paper discusses one essential trouble brought about by imbalanced training sets and presents a learning algorithm addressing this issue. The experiments (with synthetic and real-world data) focus on 2-class problems with examples described with binary and continuous attributes.</abstract></paper>