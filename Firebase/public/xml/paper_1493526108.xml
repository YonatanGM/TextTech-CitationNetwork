<paper id="1493526108"><title>NewsWeeder: learning to filter netnews</title><year>1995</year><authors><author org="School of Computer Science, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213" id="2105985910">Ken Lang</author></authors><n_citation>1332</n_citation><doc_type>Conference</doc_type><references><reference>1906479090</reference><reference>1966553486</reference><reference>1986913017</reference><reference>1995875735</reference><reference>2041404167</reference><reference>2054658115</reference><reference>2155106456</reference></references><venue id="1180662882" type="C">International Conference on Machine Learning</venue><doi>10.1016/B978-1-55860-377-6.50048-7</doi><keywords><keyword weight="0.52592">Weighting</keyword><keyword weight="0.6693">User profile</keyword><keyword weight="0.47424">Information retrieval</keyword><keyword weight="0.46288">Computer science</keyword><keyword weight="0.55018">Minimum description length</keyword><keyword weight="0.48002">Filter (signal processing)</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.47313">Machine learning</keyword></keywords><publisher>Morgan Kaufmann Publishers Inc.</publisher><abstract>Abstract A significant problem in many information filtering systems is the dependence on the user for the creation and maintenance of a user profile, which describes the useru0027s interests. NewsWeeder is a netnews-filtering system that addresses this problem by letting the user rate his or her interest level for each article being read (1-5), and then learning a user profile based on these ratings. This paper describes how NewsWeeder accomplishes this task, and examines the alternative learning methods used. The results show that a learning algorithm based on the Minimum Description Length (MDL) principle was able to raise the percentage of interesting articles to be shown to users from 14% to 52% on average. Further, this performance significantly outperformed (by 21%) one of the most successful techniques in Information Retrieval (IR), term-frequency/inverse-document-frequency (tf-idf) weighting.</abstract></paper>