<paper id="1956647075"><title>Learning mixtures of Gaussians</title><year>1999</year><authors><author org="California Univ., Berkeley, CA, USA" id="2472035779">S. Dasgupta</author></authors><n_citation>505</n_citation><doc_type>Conference</doc_type><references><reference>1976238508</reference><reference>2018799963</reference><reference>2095374884</reference><reference>2983923309</reference></references><venue id="1150208541" type="C">Foundations of Computer Science</venue><doi>10.1109/SFFCS.1999.814639</doi><keywords><keyword weight="0.49282">Dimensionality reduction</keyword><keyword weight="0.44747">Pattern recognition</keyword><keyword weight="0.4839">Polynomial</keyword><keyword weight="0.42048">Computer science</keyword><keyword weight="0.46136">Gaussian</keyword><keyword weight="0.48065">Heuristics</keyword><keyword weight="0.49891">Statistical model</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.48314">Local search (optimization)</keyword><keyword weight="0.50996">Mixture model</keyword></keywords><publisher>IEEE</publisher><abstract>Mixtures of Gaussians are among the most fundamental and widely used statistical models. Current techniques for learning such mixtures from data are local search heuristics with weak performance guarantees. We present the first provably correct algorithm for learning a mixture of Gaussians. This algorithm is very simple and returns the true centers of the Gaussians to within the precision specified by the user with high probability. It runs in time only linear in the dimension of the data and polynomial in the number of Gaussians.</abstract></paper>