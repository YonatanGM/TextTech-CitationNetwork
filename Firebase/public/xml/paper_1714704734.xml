<paper id="1714704734"><title>Ultraconservative online algorithms for multiclass problems</title><year>2003</year><authors><author org="School of Computer Science &amp; Engineering, Hebrew University, Jerusalem 91904, Israel#TAB#" id="2239053892">Koby Crammer</author><author org="School of Computer Science &amp; Engineering, Hebrew University, Jerusalem 91904, Israel#TAB#" id="2292250447">Yoram Singer</author></authors><n_citation>527</n_citation><doc_type>Journal</doc_type><references><reference>1496612019</reference><reference>1602492977</reference><reference>1676820704</reference><reference>1709057194</reference><reference>1762008180</reference><reference>1976026757</reference><reference>1979711143</reference><reference>2069317438</reference><reference>2101276256</reference><reference>2102800374</reference><reference>2119821739</reference><reference>2129113961</reference><reference>2141462139</reference><reference>2157791002</reference></references><venue id="118988714" type="J">Journal of Machine Learning Research</venue><doi>10.1162/jmlr.2003.3.4-5.951</doi><keywords><keyword weight="0.57171">Online algorithm</keyword><keyword weight="0.50495">Binary classification</keyword><keyword weight="0.63849">Margin Infused Relaxed Algorithm</keyword><keyword weight="0.46977">Algorithm</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.5404">Statistical classification</keyword><keyword weight="0.54625">Perceptron</keyword><keyword weight="0.4668">Machine learning</keyword><keyword weight="0.40866">Mathematics</keyword><keyword weight="0.60478">Weighted Majority Algorithm</keyword><keyword weight="0.63977">Multiclass classification</keyword><keyword weight="0.45765">Binary number</keyword></keywords><publisher>JMLR.org</publisher><abstract>In this paper we study a paradigm to generalize online classification algorithms for binary classification problems to multiclass problems. The particular hypotheses we investigate maintain one prototype vector per class. Given an input instance, a multiclass hypothesis computes a similarity-score between each prototype and the input instance and sets the predicted label to be the index of the prototype achieving the highest similarity. To design and analyze the learning algorithms in this paper we introduce the notion of ultraconservativeness. Ultraconservative algorithms are algorithms that update only the prototypes attaining similarity-scores which are higher than the score of the correct labelu0027s prototype. We start by describing a family of additive ultraconservative algorithms where each algorithm in the family updates its prototypes by finding a feasible solution for a set of linear constraints that depend on the instantaneous similarity-scores. We then discuss a specific online algorithm that seeks a set of prototypes which have a small norm. The resulting algorithm, which we term MIRA (for Margin Infused Relaxed Algorithm) is ultraconservative as well. We derive mistake bounds for all the algorithms and provide further analysis of MIRA using a generalized notion of the margin for multiclass problems. We discuss the form the algorithms take in the binary case and show that all the algorithms from the first family reduce to the Perceptron algorithm while MIRA provides a new Perceptron-like algorithm with a margin-dependent learning rate. We then return to multiclass problems and describe an analogous multiplicative family of algorithms with corresponding mistake bounds. We end the formal part by deriving and analyzing a multiclass version of Li and Longu0027s ROMMA algorithm. We conclude with a discussion of experimental results that demonstrate the merits of our algorithms.</abstract></paper>