<paper id="1978633512"><title>Active learning using pre-clustering</title><year>2004</year><authors><author org="University of Amsterdam Amsterdam, The Netherlands#TAB#" id="2302732485">Hieu T. Nguyen</author><author org="University of Amsterdam Amsterdam, The Netherlands#TAB#" id="92229816">Arnold Smeulders</author></authors><n_citation>321</n_citation><doc_type>Conference</doc_type><references><reference>1483816357</reference><reference>1484084878</reference><reference>1514707997</reference><reference>1514940655</reference><reference>1524688041</reference><reference>1599935123</reference><reference>1973058695</reference><reference>2043182541</reference><reference>2085989833</reference><reference>2089933214</reference><reference>2097089247</reference><reference>2113592823</reference><reference>2137054688</reference><reference>2138079527</reference><reference>2153819437</reference><reference>2167172988</reference><reference>2168822971</reference><reference>2426031434</reference></references><venue id="1180662882" type="C">International Conference on Machine Learning</venue><doi>10.1145/1015330.1015349</doi><keywords><keyword weight="0.47325">Data mining</keyword><keyword weight="0.62601">Semi-supervised learning</keyword><keyword weight="0.6382">Active learning (machine learning)</keyword><keyword weight="0.44316">Computer science</keyword><keyword weight="0.59581">Unsupervised learning</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.64885">Cluster analysis</keyword><keyword weight="0.59808">Learning classifier system</keyword><keyword weight="0.58115">Active learning</keyword><keyword weight="0.59383">Stability (learning theory)</keyword><keyword weight="0.60859">Multi-task learning</keyword><keyword weight="0.47179">Pattern recognition</keyword><keyword weight="0.47073">Machine learning</keyword></keywords><publisher>ACM</publisher><abstract>The paper is concerned with two-class active learning. While the common approach for collecting data in active learning is to select samples close to the classification boundary, better performance can be achieved by taking into account the prior data distribution. The main contribution of the paper is a formal framework that incorporates clustering into active learning. The algorithm first constructs a classifier on the set of the cluster representatives, and then propagates the classification decision to the other samples via a local noise model. The proposed model allows to select the most representative samples as well as to avoid repeatedly labeling samples in the same cluster. During the active learning process, the clustering is adjusted using the coarse-to-fine strategy in order to balance between the advantage of large clusters and the accuracy of the data representation. The results of experiments in image databases show a better performance of our algorithm compared to the current methods.</abstract></paper>