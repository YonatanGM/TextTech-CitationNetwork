<paper id="1965083026"><title>Retrieving the most similar symbolic pictures from pictorial databases</title><year>1992</year><authors><author org="Institute of Computer Science and Information Engineering, National Chung Cheng University, Chiayi, Taiwan 621, R.O.C." id="2101549130">Chin-Chen Chang</author><author org="Institute of Computer Science and Information Engineering, National Chiao Tung University, Hsinchu, Taiwan 300, R.O.C." id="2130915402">Tzong-Chen Wu</author></authors><n_citation>32</n_citation><doc_type>Journal</doc_type><references><reference>2020816363</reference><reference>2022178031</reference><reference>2046972850</reference><reference>2051922558</reference><reference>2094733886</reference><reference>2121303315</reference><reference>2157592119</reference></references><venue id="174847851" type="J">Information Processing and Management</venue><doi>10.1016/0306-4573(92)90028-X</doi><keywords><keyword weight="0.4579">Data structure</keyword><keyword weight="0.42685">Data mining</keyword><keyword weight="0.473">Similitude</keyword><keyword weight="0.40473">Indexation</keyword><keyword weight="0.43857">Information retrieval</keyword><keyword weight="0.41692">Computer science</keyword><keyword weight="0.4453">Panorama</keyword><keyword weight="0.0">Spatial relationship</keyword><keyword weight="0.47261">Search engine indexing</keyword><keyword weight="0.49009">Ordered pair</keyword><keyword weight="0.47541">Hash function</keyword><keyword weight="0.40369">Database</keyword></keywords><publisher>Pergamon Press, Inc.</publisher><abstract>In this article, we suggest an iconic indexing mechanism for spatial similarity retrieval on iconic image databases based upon the spatial relationships among the objects in a picture. The iconic objects we deal with are some kinds of gross panorama of simple objects. We also assume that any one iconic object is not distinguished from any other object of the same kind. For our mechanism, we first transform each iconic picture into a set of ordered triples (Oi, Oj, Rij) where Oi and Oj are objects and Rij is the predefined spatial relationship codes between Oi and Oj. Then we construct a set of hashing functions for all spatial relationship codes Rij, separately, associated with all ordered pairs (Oi, Oj) extracted from the ordered triples (Oi, Oj, Rij). Thereafter, an iconic index table can be established according to the constructed hashing functions for all predefined spatial relationship codes. By applying the constructed hashing functions, the most similar pictures in the database satisfying a specified query can be fast determined. We can easily extend our mechanism for handling the case when some new spatial relationship codes are defined later for the considerations of refined spatial similarity retrieval under the maximum-likelihood measure criterion.</abstract></paper>