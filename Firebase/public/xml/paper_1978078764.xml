<paper id="1978078764"><title>Generating and evaluating evaluative arguments</title><year>2006</year><authors><author org="Computer Science Department, University of British Columbia, 2366 Main Mall, Vancouver, BC Canada V6T 1Z4#TAB#" id="1132515649">Giuseppe Carenini</author><author org="Human Communication Research Centre, University of Edinburgh, 2 Buccleuch Place, Edinburgh, United Kingdom EH8 9LW#TAB#" id="2170207220">Johanna D. Moore</author></authors><n_citation>99</n_citation><doc_type>Journal</doc_type><references><reference>15101074</reference><reference>1485750786</reference><reference>1509552954</reference><reference>1513695137</reference><reference>1534972661</reference><reference>1552247913</reference><reference>1567928726</reference><reference>1573918274</reference><reference>1577418821</reference><reference>1579803652</reference><reference>1587145565</reference><reference>1597744629</reference><reference>1970346372</reference><reference>1990113515</reference><reference>1994094436</reference><reference>1998070348</reference><reference>2004404234</reference><reference>2016349609</reference><reference>2029040102</reference><reference>2031681091</reference><reference>2038909631</reference><reference>2040025108</reference><reference>2045646185</reference><reference>2088622183</reference><reference>2090818911</reference><reference>2104626902</reference><reference>2106108275</reference><reference>2114544007</reference><reference>2114924751</reference><reference>2116401686</reference><reference>2116794885</reference><reference>2124741472</reference><reference>2136458823</reference><reference>2163600070</reference><reference>2165069726</reference><reference>2786557940</reference></references><venue id="196139623" type="J">Artificial Intelligence</venue><doi>10.1016/j.artint.2006.05.003</doi><keywords><keyword weight="0.54905">Natural language generation</keyword><keyword weight="0.49773">User assistance</keyword><keyword weight="0.46017">Cognitive science</keyword><keyword weight="0.45343">Computer science</keyword><keyword weight="0.53641">Argumentation theory</keyword><keyword weight="0.55292">Computational linguistics</keyword><keyword weight="0.52474">Computational model</keyword><keyword weight="0.52045">Natural language</keyword><keyword weight="0.4499">Artificial intelligence</keyword><keyword weight="0.0">Quantitative model</keyword><keyword weight="0.4956">Human communication</keyword><keyword weight="0.44751">Machine learning</keyword></keywords><publisher>Elsevier</publisher><abstract>Evaluative arguments are pervasive in natural human communication. In countless situations people attempt to advise or persuade their interlocutors that something is desirable (vs. undesirable) or right (vs. wrong). With the proliferation of on-line systems serving as personal advisors and assistants, there is a pressing need to develop general and testable computational models for generating and presenting evaluative arguments. Previous research on generating evaluative arguments has been characterized by two major limitations. First, researchers have tended to focus only on specific aspects of the generation process. Second, the proposed approaches were not empirically tested. The research presented in this paper addresses both limitations. We have designed and implemented a complete computational model for generating evaluative arguments. For content selection and organization, we devised an argumentation strategy based on guidelines from argumentation theory. For expressing the content in natural language, we extended and integrated previous work in computational linguistics on generating evaluative arguments. The key knowledge source for both tasks is a quantitative model of user preferences. To empirically test critical aspects of our generation model, we have devised and implemented an evaluation framework in which the effectiveness of evaluative arguments can be measured with real users. Within the framework, we have performed an experiment to test two basic hypotheses on which the design of the computational model is based; namely, that our proposal for tailoring an evaluative argument to the addresseeu0027s preferences increases its effectiveness, and that differences in conciseness significantly influence argument effectiveness. The second hypothesis was confirmed in the experiment. In contrast, the first hypothesis was only marginally confirmed. However, independent testing by other researchers has recently provided further support for this hypothesis.</abstract></paper>