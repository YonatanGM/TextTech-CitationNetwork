<paper id="1977517560"><title>On the sample complexity of pac-learning using random and chosen examples</title><year>1990</year><authors><author org="MIT Laboratory for Computer Science, Cambridge, Massachussetts 02139" id="2673290930">Bonnie Eisenberg</author><author org="MIT Laboratory for Computer Science, Cambridge, Massachussetts 02139" id="695545146">Ronald L. Rivest</author></authors><n_citation>38</n_citation><doc_type>Conference</doc_type><references><reference>1989445634</reference><reference>2045313701</reference></references><venue id="1177622950" type="C">Conference on Learning Theory</venue><doi>10.1016/B978-1-55860-146-8.50015-1</doi><keywords><keyword weight="0.44047">Ask price</keyword><keyword weight="0.66449">Concept class</keyword><keyword weight="0.45498">Computer science</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.0">Sample complexity</keyword><keyword weight="0.44658">Machine learning</keyword></keywords><publisher>Morgan Kaufmann Publishers Inc.</publisher><abstract>Membership queries have been used to efficiently and exactly learn a concept class C that is too difficult to pac-learn using random examples. We ask whether using membership queries--in conjunction with or instead of random examples--can serve a new purpose: helping to reduce the total number of examples needed to pac-learn a concept class C already known to be pac-learnable using just random examples. We focus on concept classes that are dense in themselves, such as half-spaces of * , rectangles in the plane, and the class I = { [ 0, a ] : 0 # a u003e 1 } of initial segments of [0, 1].</abstract></paper>