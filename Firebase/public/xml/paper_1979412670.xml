<paper id="1979412670"><title>Selective sampling for nearest neighbor classifiers</title><year>1999</year><authors><author org="Computer Science Department, Technion, Israel Institute of Technology 32000, Haifa, Israel. mic@cs.technion.ac.il#TAB#" id="527507227">Michael Lindenbaum</author><author org="Computer Science Department, Technion, Israel Institute of Technology 32000, Haifa, Israel. shaulm@cs.technion.ac.il#TAB#" id="2243591905">Shaul Markovitch</author><author org="Computer Science Department, Technion, Israel Institute of Technology 32000, Haifa, Israel. rusakov@cs.technion.ac.il#TAB#" id="2073111854">Dmitry Rusakov</author></authors><n_citation>167</n_citation><doc_type>Conference</doc_type><references><reference>205184011</reference><reference>1513874326</reference><reference>1528361845</reference><reference>1553262910</reference><reference>1559996711</reference><reference>1573810412</reference><reference>1596179888</reference><reference>1667165204</reference><reference>1843547622</reference><reference>1850914115</reference><reference>1868985710</reference><reference>1928599218</reference><reference>2021404082</reference><reference>2080021732</reference><reference>2104597806</reference><reference>2115305054</reference><reference>2117063635</reference><reference>2122111042</reference><reference>2122496402</reference><reference>2128073546</reference><reference>2139709458</reference><reference>2147169507</reference><reference>2151023586</reference><reference>2563408008</reference></references><venue id="1184914352" type="C">National Conference on Artificial Intelligence</venue><doi>10.1023/B:MACH.0000011805.60520.fe</doi><keywords><keyword weight="0.4702">Data mining</keyword><keyword weight="0.50029">Data set</keyword><keyword weight="0.5898">Best bin first</keyword><keyword weight="0.44644">Computer science</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.49717">Nearest-neighbor chain algorithm</keyword><keyword weight="0.60949">Large margin nearest neighbor</keyword><keyword weight="0.55023">k-nearest neighbors algorithm</keyword><keyword weight="0.48447">Active learning</keyword><keyword weight="0.46333">Random field</keyword><keyword weight="0.46967">Pattern recognition</keyword><keyword weight="0.53926">Sampling (statistics)</keyword><keyword weight="0.47272">Machine learning</keyword></keywords><publisher>Kluwer Academic Publishers</publisher><abstract>In the passive, traditional, approach to learning, the information available to the learner is a set of classified examples, which are randomly drawn from the instance space. In many applications, however, the initial classification of the training set is a costly process, and an intelligently selection of training examples from unlabeled data is done by an active learner.This paper proposes a lookahead algorithm for example selection and addresses the problem of active learning in the context of nearest neighbor classifiers. The proposed approach relies on using a random field model for the example labeling, which implies a dynamic change of the label estimates during the sampling process.The proposed selective sampling algorithm was evaluated empirically on artificial and real data sets. The experiments show that the proposed method outperforms other methods in most cases.</abstract></paper>