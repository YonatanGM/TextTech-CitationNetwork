<paper id="1979071892"><title>Automatic programming of behavior-based robots using reinforcement learning</title><year>1992</year><authors><author org="IBM - T. J. Watson Research Center, Yorktown Heights, NY" id="2133778237">Sridhar Mahadevan</author><author org="IBM - T. J. Watson Research Center, Yorktown Heights, NY" id="2146356590">Jonathan Connell</author></authors><n_citation>398</n_citation><doc_type>Journal</doc_type><references><reference>50296447</reference><reference>145683767</reference><reference>1491843047</reference><reference>1507001854</reference><reference>1527418157</reference><reference>1538393421</reference><reference>1555922520</reference><reference>1567903305</reference><reference>1592402337</reference><reference>1603565927</reference><reference>2009207944</reference><reference>2061361125</reference><reference>2097856935</reference><reference>2100677568</reference><reference>2101602574</reference><reference>2104263168</reference><reference>2140606869</reference><reference>2149276032</reference><reference>2149706766</reference><reference>2154418813</reference><reference>2180885055</reference></references><venue id="196139623" type="J">Artificial Intelligence</venue><doi>10.1016/0004-3702(92)90058-6</doi><keywords><keyword weight="0.68544">Robot learning</keyword><keyword weight="0.52915">Trial and error</keyword><keyword weight="0.59934">Temporal difference learning</keyword><keyword weight="0.62538">Active learning (machine learning)</keyword><keyword weight="0.45541">Computer science</keyword><keyword weight="0.59752">Q-learning</keyword><keyword weight="0.63984">Unsupervised learning</keyword><keyword weight="0.4715">Artificial intelligence</keyword><keyword weight="0.46602">Machine learning</keyword><keyword weight="0.64001">Reinforcement learning</keyword><keyword weight="0.67451">Learning classifier system</keyword></keywords><publisher>Elsevier Science Publishers Ltd.</publisher><abstract>Abstract This paper describes a general approach for automatically programming a behavior-based robot. New behaviors are learned by trial and error using a performance feedback function as reinforcement. Two algorithms for behavior learning are described that combine Q learning, a well-known scheme for propagating reinforcement values temporally across actions, with statistical clustering and Hamming distance, two ways of propagating reinforcement values spatially across states. A real behavior-based robot called OBELIX is described that learns several component behaviors in an example task involving pushing boxes. A simulator for the box pushing task is also used to gather data on the learning techniques. A detailed experimental study using the real robot and the simulator suggests two conclusions. 1. (1) The learning techniques are able to learn the individual behaviors, sometimes outperforming a handcoded program. 2. (2) Using a behavior-based architecture speeds up reinforcement learning by converting the problem of learning a complex task into that of learning a simpler set of special-purpose reactive subtasks.</abstract></paper>