<paper id="1972073638"><title>Direct parallelization of call statements</title><year>1986</year><authors><author org="University of Illinois." id="2303936742">Rémi Triolet</author><author org="École des Mines de Paris, Paris (France)" id="1480894473">Francois Irigoin</author><author org="Univ. Paris VI, Paris, France" id="529361719">Paul Feautrier</author></authors><n_citation>155</n_citation><doc_type>Conference</doc_type><references><reference>110734221</reference><reference>2031373197</reference><reference>2043555680</reference><reference>2083546229</reference><reference>2090286414</reference><reference>2124153277</reference><reference>2132661148</reference><reference>2135736783</reference></references><venue id="1162239172" type="C">Compiler Construction</venue><doi>10.1145/12276.13329</doi><keywords><keyword weight="0.54438">Asynchronous communication</keyword><keyword weight="0.0">Graph</keyword><keyword weight="0.4756">Programming language</keyword><keyword weight="0.47874">Computer science</keyword><keyword weight="0.42838">Approximations of π</keyword><keyword weight="0.48158">Theoretical computer science</keyword><keyword weight="0.0">Data dependence</keyword></keywords><publisher>ACM</publisher><abstract>Asynchronous CALL statements are necessary in order to use more than one processor in current multiprocessors. Detecting CALL statements that may be executed in parallel is one way to fill this need. This approach requires accurate approximations of called procedure effects. This is achieved by using new objects called Region and Execution Context . An algorithm to find asynchronous CALL statements is given. It involves a new dependence test to compute data dependence graphs, which provides better results than previous ones even when no CALL statements are involved. This method has been implemented in Parafrase and preliminary results are encouraging.</abstract></paper>