<paper id="1980990528"><title>Embedding decision-analytic control in a learning architecture</title><year>1991</year><authors><author org="University of Washington-Seattle," id="57747768">Oren Etzioni</author></authors><n_citation>48</n_citation><doc_type>Journal</doc_type><references><reference>95872835</reference><reference>1510924215</reference><reference>1574350796</reference><reference>1582772526</reference><reference>1600460799</reference><reference>1966028617</reference><reference>1982722043</reference><reference>1994022788</reference><reference>1999011285</reference><reference>2012404493</reference><reference>2016616384</reference><reference>2017626051</reference><reference>2026891055</reference><reference>2031597232</reference><reference>2041683889</reference><reference>2079625074</reference><reference>2088685985</reference><reference>2123939056</reference><reference>2149706766</reference><reference>2156770822</reference><reference>2166996723</reference><reference>2171798962</reference><reference>2174370050</reference><reference>2989552998</reference></references><venue id="196139623" type="J">Artificial Intelligence</venue><doi>10.1016/0004-3702(91)90008-8</doi><keywords><keyword weight="0.47393">Deliberation</keyword><keyword weight="0.51034">Heuristic</keyword><keyword weight="0.46134">Architecture</keyword><keyword weight="0.59983">Autonomous agent</keyword><keyword weight="0.49867">Programmer</keyword><keyword weight="0.4433">Embedding</keyword><keyword weight="0.57037">Expected utility hypothesis</keyword><keyword weight="0.0">Learning architecture</keyword><keyword weight="0.4642">Operations research</keyword><keyword weight="0.4608">Artificial intelligence</keyword><keyword weight="0.45562">Machine learning</keyword><keyword weight="0.384">Mathematics</keyword></keywords><publisher>Elsevier</publisher><abstract>Abstract An autonomous agentu0027s control problem is often formulated as the attempt to minimize the expected cost of accomplishing a goal. This paper presents a three-dimensional view of the control problem that is substantially more realistic. The agentu0027s control policy is assessed along three dimensions: deliberation cost, execution cost, and goal value. The agent must choose which goal to attend to as well as which action to take. Our control policy seeks to maximize satisfaction by trading execution cost and goal value while keeping deliberation cost low. The agentu0027s control decisions are guided by the MU heuristicâ€”choose the alternative whose marginal expected utility is maximal. Thus, when necessary, the agent will prefer easily-achieved goals to attractive but difficult-to-attain alternatives. The MU heuristic is embedded in an architecture with record-keeping and learning capabilities. The architecture offers its control module expected utility and expected cost estimates that are gradually refined as the agent accumulates experience. A programmer is not required to supply that knowledge, and the estimates are provided without recourse to distributional assumptions.</abstract></paper>