<paper id="1966476169"><title>Sparse matrix computations on parallel processor arrays</title><year>1993</year><authors><author org="" id="2655810616">Andrew T. Ogielski</author><author org="" id="1971187209">William Aiello</author></authors><n_citation>63</n_citation><doc_type>Journal</doc_type><references><reference>2029342163</reference><reference>2080038255</reference><reference>2152033109</reference></references><venue id="165512578" type="J">SIAM Journal on Scientific Computing</venue><doi>10.1137/0914033</doi><keywords><keyword weight="0.59302">Row and column spaces</keyword><keyword weight="0.58931">Processor array</keyword><keyword weight="0.40748">Computer science</keyword><keyword weight="0.52264">Parallel algorithm</keyword><keyword weight="0.55839">Massively parallel</keyword><keyword weight="0.53148">Matrix (mathematics)</keyword><keyword weight="0.45786">Parallel computing</keyword><keyword weight="0.52885">Vector processor</keyword><keyword weight="0.57007">Matrix multiplication</keyword><keyword weight="0.55573">Sparse matrix</keyword></keywords><publisher>Society for Industrial and Applied Mathematics</publisher><abstract>This paper investigates the balancing of distributed compressed storage of large sparse matrices on a massively parallel computer. For fast computation of matrix–vector and matrix–matrix products on a rectangular processor array with efficient communications along its rows and columns it is required that the nonzero elements of each matrix row or column be distributed among the processors located within the same array row or column, respectively. Randomized packing algorithms are constructed with such properties, and it is proved that with high probability the algorithms produce well-balanced storage for sufficiently large matrices with bounded number of nonzeros in each row and column, but no other restrictions on structure. Then basic matrix–vector multiplication routines are described with fully parallel interprocessor communications and intraprocessor gather and scatter operations. Their efficiency isdemonstrated on the 16,384-processor MasPar computer.</abstract></paper>