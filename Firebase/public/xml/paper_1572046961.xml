<paper id="1572046961"><title>Load Balancing for Parallel Query Execution on NUMA Multiprocessors</title><year>1999</year><authors><author org="INRIA Rocquencourt, France. E-mail: luc.bouganim@inria.fr#TAB#" id="2296668023">Luc Bouganim</author><author org="INRIA Rocquencourt, France. E-mail: daniela.florescu@inria.fr#TAB#" id="2061024894">Daniela Florescu</author><author org="INRIA Rocquencourt, France. E-mail: patrick.valduriez@inria.fr#TAB#" id="2223920688">Patrick Valduriez</author></authors><n_citation>13</n_citation><doc_type>Journal</doc_type><references><reference>158628092</reference><reference>1508957747</reference><reference>1520750340</reference><reference>1522704666</reference><reference>1535462869</reference><reference>1545720031</reference><reference>1549426500</reference><reference>1557445129</reference><reference>1557956086</reference><reference>1578006587</reference><reference>1581128986</reference><reference>1585614323</reference><reference>1597532222</reference><reference>1604793072</reference><reference>1605782097</reference><reference>1970196737</reference><reference>1975025054</reference><reference>1997020216</reference><reference>2034408574</reference><reference>2037394610</reference><reference>2039795706</reference><reference>2049263029</reference><reference>2057552436</reference><reference>2068088848</reference><reference>2078528123</reference><reference>2080427212</reference><reference>2104777670</reference><reference>2113313004</reference><reference>2122100378</reference><reference>2127547524</reference><reference>2130570354</reference><reference>2131886407</reference><reference>2134164294</reference><reference>2136572251</reference><reference>2151197771</reference><reference>2151834759</reference><reference>2152056423</reference><reference>2160454978</reference><reference>2163738478</reference><reference>2164851674</reference><reference>2170432588</reference><reference>2171922437</reference><reference>2294693415</reference></references><venue id="35927321" type="J">Distributed and Parallel Databases</venue><doi>10.1023/A:1008642513285</doi><keywords><keyword weight="0.5161">Pipeline (computing)</keyword><keyword weight="0.52273">Load balancing (computing)</keyword><keyword weight="0.41431">Idle</keyword><keyword weight="0.43649">Computer science</keyword><keyword weight="0.46654">Parallel computing</keyword><keyword weight="0.62141">Cache-only memory architecture</keyword><keyword weight="0.43771">Real-time computing</keyword><keyword weight="0.43319">Exploit</keyword><keyword weight="0.5297">Execution model</keyword><keyword weight="0.47703">Skew</keyword><keyword weight="0.56902">Non-uniform memory access</keyword><keyword weight="0.45623">Distributed computing</keyword></keywords><publisher>Kluwer Academic Publishers</publisher><abstract>To scale up to high-end configurations, shared-memory multiprocessors are evolving towards Non Uniform Memory Access (NUMA) architectures. In this paper, we address the central problem of load balancing during parallel query execution in NUMA multiprocessors. We first show that an execution model for NUMA should not use data partitioning (as shared-nothing systems do) but should strive to exploit efficient shared-memory strategies like Synchronous Pipelining (SP). However, SP has problems in NUMA, especially with skewed data. Thus, we propose a new execution strategy which solves these problems. The basic idea is to allow partial materialization of intermediate results and to make them progressivly public, i.e., able to be processed by any processor, as needed to avoid processor idle times. Hence, we call this strategy Progressive Sharing (PS). We conducted a performance comparison using an implementation of SP and PS on a 72-processor KSR1 computer, with many queries and large relations. With no skew, SP and PS have both linear speed-up. However, the impact of skew is very severe on SP performance while it is insignificant on PS. Finally, we show that, in NUMA, PS can also be beneficial in executing several pipeline chains concurrently.</abstract></paper>