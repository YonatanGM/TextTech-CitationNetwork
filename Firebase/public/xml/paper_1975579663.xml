<paper id="1975579663"><title>Exploring Content Models for Multi-Document Summarization</title><year>2009</year><authors><author org="UC Berkeley#TAB#" id="2111029421">Aria Haghighi</author><author org="Microsoft Research,#TAB#" id="2006711911">Lucy Vanderwende</author></authors><n_citation>322</n_citation><doc_type>Conference</doc_type><references><reference>154314666</reference><reference>1537217019</reference><reference>1880262756</reference><reference>1973894278</reference><reference>1974339500</reference><reference>1989420837</reference><reference>1990991664</reference><reference>2027823133</reference><reference>2082512208</reference><reference>2101075799</reference><reference>2103339462</reference><reference>2109857522</reference><reference>2110693578</reference><reference>2110983154</reference><reference>2118370253</reference><reference>2132827946</reference><reference>2152992673</reference><reference>2169546346</reference><reference>2169606435</reference><reference>2952883787</reference></references><venue id="1173951661" type="C">North American Chapter of the Association for Computational Linguistics</venue><doi>10.3115/1620754.1620807</doi><keywords><keyword weight="0.44046">Computer science</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.47062">Natural language processing</keyword><keyword weight="0.48695">Probabilistic logic</keyword><keyword weight="0.44974">Hierarchy</keyword><keyword weight="0.52221">Discriminative model</keyword><keyword weight="0.48948">Pairwise comparison</keyword><keyword weight="0.60411">Multi-document summarization</keyword><keyword weight="0.62018">Automatic summarization</keyword><keyword weight="0.48587">Word lists by frequency</keyword><keyword weight="0.46501">Information retrieval</keyword><keyword weight="0.47936">Vocabulary</keyword><keyword weight="0.45977">Machine learning</keyword></keywords><publisher>Association for Computational Linguistics</publisher><abstract>We present an exploration of generative probabilistic models for multi-document summarization. Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way. Our final model, HierSum, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions. At the task of producing generic DUC-style summaries, HierSum yields state-of-the-art ROUGE performance and in pairwise user evaluation strongly outperforms Toutanova et al. (2007)u0027s state-of-the-art discriminative system. We also explore HierSumu0027s capacity to produce multiple u0027topical summariesu0027 in order to facilitate content discovery and navigation.</abstract></paper>