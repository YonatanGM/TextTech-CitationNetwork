<paper id="1977245551"><title>Learning and making decisions when costs and probabilities are both unknown</title><year>2001</year><authors><author org="University of California, San Diego; La Jolla California" id="54648453">Bianca Zadrozny</author><author org="University of California, San Diego; La Jolla California" id="705676171">Charles Elkan</author></authors><n_citation>336</n_citation><doc_type>Conference</doc_type><references><reference>167016754</reference><reference>1503605645</reference><reference>1507029541</reference><reference>1549238650</reference><reference>1596992398</reference><reference>1598033630</reference><reference>1607965943</reference><reference>2058732827</reference><reference>2096942889</reference><reference>2111022379</reference><reference>2152761983</reference><reference>2912934387</reference></references><venue id="1130985203" type="C">Knowledge Discovery and Data Mining</venue><doi>10.1145/502512.502540</doi><keywords><keyword weight="0.45635">Econometrics</keyword><keyword weight="0.45269">Data mining</keyword><keyword weight="0.56536">Decision tree</keyword><keyword weight="0.5203">Random variable</keyword><keyword weight="0.44242">Computer science</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.51052">Cluster analysis</keyword><keyword weight="0.49683">Collaborative filtering</keyword><keyword weight="0.53602">Naive Bayes classifier</keyword><keyword weight="0.42117">CONTEST</keyword><keyword weight="0.45977">Machine learning</keyword><keyword weight="0.53129">Selection bias</keyword><keyword weight="0.52618">Estimator</keyword></keywords><publisher>ACM</publisher><abstract>In many data mining domains, misclassification costs are different for different examples, in the same way that class membership probabilities are example-dependent. In these domains, both costs and probabilities are unknown for test examples, so both cost estimators and probability estimators must be learned. After discussing how to make optimal decisions given cost and probability estimates, we present decision tree and naive Bayesian learning methods for obtaining well-calibrated probability estimates. We then explain how to obtain unbiased estimators for example-dependent costs, taking into account the difficulty that in general, probabilities and costs are not independent random variables, and the training examples for which costs are known are not representative of all examples. The latter problem is called sample selection bias in econometrics. Our solution to it is based on Nobel prize-winning work due to the economist James Heckman. We show that the methods we propose perform better than MetaCost and all other known methods, in a comprehensive experimental comparison that uses the well-known, large, and challenging dataset from the KDDu002798 data mining contest.</abstract></paper>