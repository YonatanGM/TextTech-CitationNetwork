<paper id="1520377376"><title>An Algorithm that Learns What‘s in a Name</title><year>1999</year><authors><author org="BBN Systems and Technologies, 70 Fawcett Street, Cambridge MA 02138. dbikel@seas.upenn.edu#TAB#" id="686579444">Daniel M. Bikel</author><author org="BBN Systems and Technologies, 70 Fawcett Street, Cambridge MA 02138. schwartz@bbn.com#TAB#" id="2105897744">Richard Schwartz</author><author org="BBN Systems and Technologies, 70 Fawcett Street, Cambridge MA 02138. weisched@bbn.com#TAB#" id="2307223523">Ralph M. Weischedel</author></authors><n_citation>699</n_citation><doc_type>Journal</doc_type><references><reference>1568095077</reference><reference>1568620938</reference><reference>1718065290</reference><reference>1971763646</reference><reference>1991133427</reference><reference>2033209333</reference><reference>2039276255</reference><reference>2059192419</reference><reference>2080856991</reference><reference>2099247782</reference><reference>2117400858</reference><reference>2138425667</reference></references><venue id="62148650" type="J">Machine Learning</venue><doi>10.1023/A:1007558221122</doi><keywords><keyword weight="0.0">Training set</keyword><keyword weight="0.45119">Broadcasting</keyword><keyword weight="0.46238">Computer science</keyword><keyword weight="0.44448">Algorithm</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.0">Controlled experiment</keyword><keyword weight="0.59503">Hidden Markov model</keyword><keyword weight="0.4764">Machine learning</keyword></keywords><publisher>Kluwer Academic Publishers</publisher><abstract>In this paper, we present IdentiFinderTM, a hidden Markov model that learns to recognize and classify names, dates, times, and numerical quantities. We have evaluated the model in English (based on data from the Sixth and Seventh Message Understanding Conferences [MUC-6, MUC-7] and broadcast news) and in Spanish (based on data distributed through the First Multilingual Entity Task [MET-1]), and on speech input (based on broadcast news). We report results here on standard materials only to quantify performance on data available to the community, namely, MUC-6 and MET-1. Results have been consistently better than reported by any other learning algorithm. IdentiFinder‘s performance is competitive with approaches based on handcrafted rules on mixed case text and superior on text where case information is not available. We also present a controlled experiment showing the effect of training set size on performance, demonstrating that as little as 100,000 words of training data is adequate to get performance around 90% on newswire. Although we present our understanding of why this algorithm performs so well on this class of problems, we believe that significant improvement in performance may still be possible.</abstract></paper>