<paper id="1600188822"><title>Image-based Rendering with Controllable Illumination</title><year>1997</year><authors><author org="The Chinese Univ. of Hong Kong" id="2169748419">Tien-Tsin Wong</author><author org="The Chinese Univ. of Hong Kong" id="2166341251">Pheng-Ann Heng</author><author org="The Chinese Univ. of Hong Kong" id="2131344389">Siu-Hang Or</author><author org="The Chinese Univ. of Hong Kong" id="2143434760">Wai-Yin Ng</author></authors><n_citation>109</n_citation><doc_type>Conference</doc_type><references><reference>2000928589</reference><reference>2062737404</reference><reference>2063366997</reference><reference>2098362450</reference><reference>2104917647</reference><reference>2111169574</reference><reference>2122909153</reference><reference>2144736368</reference><reference>2153160066</reference><reference>2157500953</reference><reference>2294985758</reference></references><venue id="1200430907" type="C">Eurographics Symposium on Rendering Techniques</venue><doi>10.1007/978-3-7091-6858-5_2</doi><keywords><keyword weight="0.48106">Bidirectional reflectance distribution function</keyword><keyword weight="0.4573">Computer vision</keyword><keyword weight="0.5861">Texture mapping</keyword><keyword weight="0.45579">Computer graphics (images)</keyword><keyword weight="0.39064">Computer science</keyword><keyword weight="0.43901">Spherical harmonics</keyword><keyword weight="0.51323">Light field</keyword><keyword weight="0.49926">Perspective (graphical)</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.53325">Pixel</keyword><keyword weight="0.65911">Image-based modeling and rendering</keyword><keyword weight="0.62584">Rendering (computer graphics)</keyword></keywords><publisher>Springer, Vienna</publisher><abstract>A new image-based rendering method, based on the light field and Lumigraph system, allows illumination to be changed interactively. It does not try to recover or use any geometrical information (e.g., depth or surface normals) to calculate the illumination, but the resulting images are physically correct. The scene is first sampled from different viewpoints and under different illuminations. Treating each pixel on the back plane of the light slab as a surface element,the sampled images are used to find an apparent BRDF of each surface element. The tabular BRDF data of each pixel is further transformed to the spherical harmonic domain for efficient storage. Whenever the user changes the illumination setting, a certain number of views are reconstructed. The correct user perspective view is then displayed using the texture mapping technique of the Lumigraph system. Hence, the intensity, the type and the number of the light sources can be manipulated interactively.</abstract></paper>