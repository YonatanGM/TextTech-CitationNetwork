<paper id="1612155886"><title>Real-world Data is Dirty: Data Cleansing and The Merge/Purge Problem</title><year>1998</year><authors><author org="Dept. of Comput. Sci., Columbia Univ., New York, NY#TAB#" id="2778563124">Mauricio A. Hernández</author><author org="Dept. of Comput. Sci., Columbia Univ., New York, NY#TAB#" id="2021877992">Salvatore J. Stolfo</author></authors><n_citation>706</n_citation><doc_type>Journal</doc_type><references><reference>1768893245</reference><reference>2010595692</reference><reference>2020191321</reference><reference>2024770506</reference><reference>2029131452</reference><reference>2034163998</reference><reference>2070771945</reference><reference>2084177971</reference><reference>2089634871</reference><reference>2127966138</reference><reference>2148179848</reference><reference>2163598528</reference><reference>2404336203</reference></references><venue id="121920818" type="J">Data Mining and Knowledge Discovery</venue><doi>10.1023/A:1009761603038</doi><keywords><keyword weight="0.47448">Semantic integration</keyword><keyword weight="0.46176">Data mining</keyword><keyword weight="0.63747">Data cleansing</keyword><keyword weight="0.46055">Computer science</keyword><keyword weight="0.35334">Purge</keyword><keyword weight="0.49112">Decision support system</keyword><keyword weight="0.48746">Sorting</keyword><keyword weight="0.58791">Dirty data</keyword><keyword weight="0.0">Merge (version control)</keyword><keyword weight="0.46941">Transitive closure</keyword></keywords><publisher>Kluwer Academic Publishers</publisher><abstract>The problem of merging multiple databases of information about common entities is frequently encountered in KDD and decision support applications in large commercial and government organizations. The problem we study is often called the Merge/Purge problem and is difficult to solve both in scale and accuracy. Large repositories of data typically have numerous duplicate information entries about the same entities that are difficult to cull together without an intelligent ’’equational theory‘‘ that identifies equivalent items by a complex, domain-dependent matching process. We have developed a system for accomplishing this Data Cleansing task and demonstrate its use for cleansing lists of names of potential customers in a direct marketing-type application. Our results for statistically generated data are shown to be accurate and effective when processing the data multiple times using different keys for sorting on each successive pass. Combing results of individual passes using transitive closure over the independent results, produces far more accurate results at lower cost. The system provides a rule programming module that is easy to program and quite good at finding duplicates especially in an environment with massive amounts of data. This paper details improvements in our system, and reports on the successful implementation for a real-world database that conclusively validates our results previously achieved for statistically generated data.</abstract></paper>