<paper id="1972002191"><title>A fast algorithm for the transient reward distribution in continuous-time Markov chains</title><year>2000</year><authors><author org="Department of Econometrics, Vrije Universiteit, De Boelelaan, 1081 HV Amsterdam, The Netherlands#TAB#" id="1980442760">H.C Tijms</author><author org="ORTEC Consultants, P.O. Box 490,2800 AL Gouda, The Netherlands#TAB#" id="2607156693">R Veldman</author></authors><n_citation>22</n_citation><doc_type>Journal</doc_type><references><reference>1967497793</reference><reference>2121314685</reference></references><venue id="27769002" type="J">Operations Research Letters</venue><doi>10.1016/S0167-6377(00)00023-7</doi><keywords><keyword weight="0.54222">Discretization</keyword><keyword weight="0.61718">Markov chain mixing time</keyword><keyword weight="0.45358">Mathematical optimization</keyword><keyword weight="0.61012">Forward algorithm</keyword><keyword weight="0.59811">Markov chain Monte Carlo</keyword><keyword weight="0.62968">Markov model</keyword><keyword weight="0.4146">Computer science</keyword><keyword weight="0.62431">Markov chain</keyword><keyword weight="0.46296">Algorithm</keyword><keyword weight="0.59992">Balance equation</keyword><keyword weight="0.59685">Hidden Markov model</keyword></keywords><publisher>Elsevier</publisher><abstract>This note presents a generally applicable discretization method for computing the transient distribution of the cumulative reward in a continuous-time Markov chain. A key feature of the algorithm is an error estimate for speeding up the calculations. The algorithm is easy to program and is numerically stable.</abstract></paper>