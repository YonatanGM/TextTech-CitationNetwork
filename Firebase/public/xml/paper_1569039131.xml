<paper id="1569039131"><title>Learning from data with bounded inconsistency</title><year>1990</year><authors><author org="Rutgers University" id="2151078108">Haym Hirsh</author></authors><n_citation>11</n_citation><doc_type>Conference</doc_type><references><reference>1498110080</reference><reference>1533943506</reference><reference>1540364590</reference><reference>1994022788</reference><reference>2009207944</reference><reference>2074256349</reference></references><venue id="1180662882" type="C">International Conference on Machine Learning</venue><doi>10.1007/978-1-4613-1557-5_4</doi><keywords><keyword weight="0.0">Concept description language</keyword><keyword weight="0.46826">Computer science</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.46357">Machine learning</keyword><keyword weight="0.55135">Bounded function</keyword><keyword weight="0.0">Version space</keyword></keywords><publisher>Morgan Kaufmann Publishers Inc.</publisher><abstract>When no single concept definition in the description language can distinguish between all the positive examples and all the negative examples, the data are said to be inconsistent with respect to the concept description language. In such cases no learner will be able to find a description classifying all instances correctly. In general, learning systems must generate reasonable results even when there is no concept definition consistent with all the data.</abstract></paper>