<paper id="1574111330"><title>Generalization Performance of Classifiers in Terms of Observed Covering Numbers</title><year>1999</year><authors><author org="Univ. of London#TAB#" id="2215287472">John Shawe-Taylor</author><author org="Australian Nat. University" id="2639031727">Nello Cristianini</author></authors><n_citation>20</n_citation><doc_type>Conference</doc_type><references><reference>2017753243</reference><reference>2026548783</reference><reference>2094062207</reference><reference>2099579348</reference><reference>2106491486</reference><reference>2108136473</reference><reference>2119821739</reference><reference>2129192653</reference><reference>2147187803</reference></references><venue id="2740279309" type="C">European Conference on Computational Learning Theory</venue><doi>10.1007/3-540-49097-3_22</doi><keywords><keyword weight="0.49022">Data point</keyword><keyword weight="0.45443">Discrete mathematics</keyword><keyword weight="0.47052">A priori and a posteriori</keyword><keyword weight="0.48356">Support vector machine</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.4613">Structural risk minimization</keyword><keyword weight="0.47226">Gramian matrix</keyword><keyword weight="0.48145">Statistical theory</keyword><keyword weight="0.46877">Classifier (linguistics)</keyword><keyword weight="0.42089">Machine learning</keyword><keyword weight="0.43338">Mathematics</keyword><keyword weight="0.48846">Eigenvalues and eigenvectors</keyword></keywords><publisher>Springer-Verlag</publisher><abstract>It is known that the covering numbers of a function class on a double sample (length 2m) can be used to bound the generalization performance of a classifier by using a margin based analysis. In this paper we show that one can utilize an analogous argument in terms of the observed covering numbers on a single m-sample (being the actual observed data points). The significance of this is that for certain interesting classes of functions, such as support vector machines, there are new techniques which allow one to find good estimates for such covering numbers in terms of the speed of decay of the eigenvalues of a Gram matrix. These covering numbers can be much less than a priori bounds indicate in situations where the particular data received is "easy". The work can be considered an extension of previous results which provided generalization performance bounds in terms of the VC-dimension of the class of hypotheses restricted to the sample, with the considerable advantage that the covering numbers can be readily computed, and they often are small.</abstract></paper>