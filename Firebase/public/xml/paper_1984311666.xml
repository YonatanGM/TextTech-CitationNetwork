<paper id="1984311666"><title>Performance engineering of the World Wide Web: application to dimensioning and cache design</title><year>1996</year><authors><author org="INRIA, B.P. 93, 06902 Sophia-Antipolis Cedex, France" id="2251933993">Jean-Chrysostome Bolot</author><author org="INRIA, B.P. 93, 06902 Sophia-Antipolis Cedex, France" id="2308548665">Philipp Hoschka</author></authors><n_citation>98</n_citation><doc_type>Conference</doc_type><references><reference>1527961683</reference><reference>1579489005</reference><reference>1974817122</reference><reference>2015945223</reference><reference>2044236594</reference><reference>2049994230</reference><reference>2066782797</reference><reference>2104460994</reference><reference>2137555637</reference></references><venue id="1135342153" type="C">The Web Conference</venue><doi>10.1016/0169-7552(96)00073-6</doi><keywords><keyword weight="0.54611">Web traffic</keyword><keyword weight="0.43869">World Wide Web</keyword><keyword weight="0.46536">Performance engineering</keyword><keyword weight="0.4596">Computer science</keyword><keyword weight="0.58282">Cache</keyword><keyword weight="0.46982">Computer network</keyword><keyword weight="0.46022">Real-time computing</keyword><keyword weight="0.48373">CPU power dissipation</keyword><keyword weight="0.442">Autoregressive integrated moving average</keyword><keyword weight="0.45201">Bandwidth (signal processing)</keyword><keyword weight="0.58325">Dimensioning</keyword><keyword weight="0.62673">Web server</keyword></keywords><publisher>Elsevier Science Publishers B. V.</publisher><abstract>Abstract The quality of the service provided by the World Wide Web, namely convenient access to a tremendous amount of information in remote locations, depends in an important way on the time required to retrieve this information. This time in turn depends on a number of parameters, in particular the load at the server and in the network. Overloads are avoided by carefully dimensioning the server (so that it has enough resources such as CPU power and disk space to handle expected requests) and the network (so that it has enough resources such as bandwidth and buffers to transport requests and replies), and by using mechanisms such as caching that minimize the resource requirements of user requests. In this paper, we consider performance issues related to dimensioning and caching. Our contribution is twofold. Regarding dimensioning, we advocate the use of time series analysis techniques for Web traffic modeling and forecasting. We show using experimental data that quantities of interest such as the number of Web requests handled by a server, or the amount of data retrieved per hour by a server, can be accurately modeled with time series such as seasonal ARIMA models. We then use these models to make medium-term predictions of client requests characteristics (number of such requests and size of document retrieved), which in turn can be used as a basis for dimensioning decisions. Regarding caching, we advocate the use of novel cache replacement algorithms that explicitly take document size and network load into account so as to minimize the retrieval time perceived by clients.</abstract></paper>