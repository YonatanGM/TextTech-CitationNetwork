<paper id="1860991815"><title>Dependency networks for inference, collaborative filtering, and data visualization</title><year>2001</year><authors><author org="Microsoft Research One Microsoft Way Redmond, WA" id="2021640924">David Heckerman</author><author org="Microsoft Research One Microsoft Way Redmond, WA" id="659530374">David Maxwell Chickering</author><author org="Microsoft Research One Microsoft Way Redmond, WA" id="2422299352">Christopher Meek</author><author org="Microsoft Research One Microsoft Way Redmond, WA" id="1974613367">Robert Rounthwaite</author><author org="Microsoft Research One Microsoft Way Redmond, WA" id="297969600">Carl Kadie</author></authors><n_citation>470</n_citation><doc_type>Journal</doc_type><references><reference>2013567125</reference><reference>2107419735</reference><reference>2110325612</reference><reference>2155106456</reference><reference>2159080219</reference><reference>2170858534</reference></references><venue id="118988714" type="J">Journal of Machine Learning Research</venue><doi>10.1162/153244301753344614</doi><keywords><keyword weight="0.47255">Data mining</keyword><keyword weight="0.4551">Computer science</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.60717">Bayesian statistics</keyword><keyword weight="0.61954">Variable-order Bayesian network</keyword><keyword weight="0.46107">Pattern recognition</keyword><keyword weight="0.66156">Bayesian network</keyword><keyword weight="0.62039">Influence diagram</keyword><keyword weight="0.62088">Dependency network</keyword><keyword weight="0.66718">Graphical model</keyword><keyword weight="0.47306">Machine learning</keyword><keyword weight="0.61332">Dynamic Bayesian network</keyword><keyword weight="0.56257">Bayesian probability</keyword></keywords><publisher>JMLR.org</publisher><abstract>We describe a graphical model for probabilistic relationships--an alternative to the Bayesian network--called a dependency network. The graph of a dependency network, unlike a Bayesian network, is potentially cyclic. The probability component of a dependency network, like a Bayesian network, is a set of conditional distributions, one for each node given its parents. We identify several basic properties of this representation and describe a computationally efficient procedure for learning the graph and probability components from data. We describe the application of this representation to probabilistic inference, collaborative filtering (the task of predicting preferences), and the visualization of acausal predictive relationships.</abstract></paper>