<paper id="1984121732"><title>The Randomization Technique as a Modeling Tool and Solution Procedure for Transient Markov Processes</title><year>1984</year><authors><author org="The George Washington University , Washington, D. C" id="2151712318">Donald Gross</author><author org="The George Washington University , Washington, D. C" id="2571465574">Douglas R. Miller</author></authors><n_citation>386</n_citation><doc_type>Journal</doc_type><references><reference>1967986582</reference><reference>1989079570</reference><reference>2011124028</reference><reference>2084953600</reference><reference>2094466033</reference><reference>2152530926</reference><reference>2161297030</reference></references><venue id="125775545" type="J">Operations Research</venue><doi>10.1287/opre.32.2.343</doi><keywords><keyword weight="0.45031">Mathematical optimization</keyword><keyword weight="0.67508">Markov process</keyword><keyword weight="0.65093">Markov property</keyword><keyword weight="0.66004">Markov model</keyword><keyword weight="0.67717">Markov chain</keyword><keyword weight="0.65337">Variable-order Markov model</keyword><keyword weight="0.63881">Discrete phase-type distribution</keyword><keyword weight="0.66686">Markov kernel</keyword><keyword weight="0.39389">Mathematics</keyword><keyword weight="0.65873">Markov renewal process</keyword></keywords><publisher>INFORMS</publisher><abstract>We present a randomization procedure for computing transient solutions to discrete state space, continuous time Markov processes. This procedure computes transient state probabilities. It is based on a construction relating a continuous time Markov process to a discrete time Markov chain. Modifications and extensions of the randomization method allow for computation of distributions of first passage times and sojourn times in Markov processes, and also the computation of expected cumulative occupancy times and expected number of events occurring during a time interval. Several implementations of the randomization procedure are discussed. In particular we present an implementation for a general class of Markov processes that can be described in terms of state space S, event set E, rate vectors R, and target vectors T-abbreviated as SERT. This general approach can handle systems whose state spaces are quite large, if they have sparse generators.</abstract></paper>