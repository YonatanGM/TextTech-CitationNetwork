<paper id="1587559447"><title>Kernel principal component analysis</title><year>1997</year><authors><author org="Max-Planck-Institut f. biol. Kybernetik" id="297432538">Bernhard Schölkopf</author><author org="GMD FIRST" id="1972291593">Alexander J. Smola</author><author org="GMD FIRST" id="2012736320">Klaus-Robert Müller</author></authors><n_citation>1291</n_citation><doc_type>Conference</doc_type><references><reference>1548139318</reference><reference>2087347434</reference><reference>2102909657</reference><reference>2119821739</reference><reference>2135463994</reference><reference>2137291015</reference><reference>2140095548</reference></references><venue id="1158833223" type="C">International Conference on Artificial Neural Networks</venue><doi>10.1007/BFb0020217</doi><keywords><keyword weight="0.60363">k-nearest neighbors algorithm</keyword><keyword weight="0.62553">Dimensionality reduction</keyword><keyword weight="0.46197">Pattern recognition</keyword><keyword weight="0.61695">Principal component regression</keyword><keyword weight="0.42192">Computer science</keyword><keyword weight="0.6205">Kernel embedding of distributions</keyword><keyword weight="0.71763">Kernel principal component analysis</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.63608">Kernel method</keyword><keyword weight="0.43467">Machine learning</keyword><keyword weight="0.5809">Principal component analysis</keyword><keyword weight="0.59326">Kernel (statistics)</keyword></keywords><publisher>Springer</publisher><abstract>A new method for performing a nonlinear form of Principal Component Analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in highdimensional feature spaces, related to input space by some nonlinear map; for instance the space of all possible d-pixel products in images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.</abstract></paper>