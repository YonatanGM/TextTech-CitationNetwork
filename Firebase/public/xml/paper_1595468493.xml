<paper id="1595468493"><title>Reducing misclassification costs</title><year>1994</year><authors><author org="Department of Information and Computer Science, University of California, Irvine, Irvine, CA 92717 pazzani, cmerz, pmurphy, ali, hume" id="1996789426">Michael J. Pazzani</author><author org="Department of Information and Computer Science, University of California, Irvine, Irvine, CA 92717 pazzani, cmerz, pmurphy, ali, hume" id="2103435164">Christopher J. Merz</author><author org="Department of Information and Computer Science, University of California, Irvine, Irvine, CA 92717 pazzani, cmerz, pmurphy, ali, hume" id="2174874735">Patrick M. Murphy</author><author org="Department of Information and Computer Science, University of California, Irvine, Irvine, CA 92717 pazzani, cmerz, pmurphy, ali, hume" id="2465769383">Kamal M. Ali</author><author org="Department of Information and Computer Science, University of California, Irvine, Irvine, CA 92717 pazzani, cmerz, pmurphy, ali, hume" id="2686223844">Timothy Hume</author><author org="Department of Information and Computer Science, University of California, Irvine, Irvine, CA 92717 pazzani, cmerz, pmurphy, ali, hume" id="2012163064">Clifford Brunk</author></authors><n_citation>265</n_citation><doc_type>Conference</doc_type><references><reference>165133269</reference><reference>175299670</reference><reference>1498913295</reference><reference>1512628935</reference><reference>1566979128</reference><reference>1999138184</reference><reference>2089967664</reference><reference>2125055259</reference><reference>2128420091</reference><reference>2136000097</reference><reference>2149706766</reference><reference>2912610563</reference></references><venue id="1180662882" type="C">International Conference on Machine Learning</venue><doi>10.1016/B978-1-55860-335-6.50034-9</doi><keywords><keyword weight="0.0">Ordered set</keyword><keyword weight="0.45042">Data mining</keyword><keyword weight="0.57748">Inductive bias</keyword><keyword weight="0.56865">Multi-task learning</keyword><keyword weight="0.46219">Reduced cost</keyword><keyword weight="0.44709">Computer science</keyword><keyword weight="0.5459">Decision list</keyword><keyword weight="0.4551">Domain theory</keyword><keyword weight="0.43079">Prefix</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.5338">Overfitting</keyword><keyword weight="0.45718">Machine learning</keyword></keywords><publisher>Morgan Kaufmann</publisher><abstract>We explore algorithms for learning classification procedures that attempt to minimize the cost of misclassifying examples. First, we consider inductive learning of classification rules. The Reduced Cost Ordering algorithm, a new method for creating a decision list (i.e., an ordered set of rules) is described and compared to a variety of inductive learning approaches. Next, we describe approaches that attempt to minimize costs while avoiding overfitting, and introduce the Clause Prefix method for pruning decision lists. Finally, we consider reducing misclassification costs when a prior domain theory is available.</abstract></paper>