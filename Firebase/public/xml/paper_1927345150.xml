<paper id="1927345150"><title>Rule induction with CN2: some recent improvements</title><year>1991</year><authors><author org="The Turing Institute, Glasgow," id="2148981713">Peter Clark</author><author org="The Turing Institute, Glasgow," id="2100204105">Robin Boswell</author></authors><n_citation>738</n_citation><doc_type /><references><reference>5667951</reference><reference>78121749</reference><reference>203696055</reference><reference>1570286060</reference><reference>1602363634</reference><reference>1861161664</reference><reference>1969223365</reference><reference>2128420091</reference><reference>2136000097</reference><reference>2428981601</reference></references><venue id="" type="">EWSL'91 Proceedings of the 5th European Conference on European Working Session on Learning</venue><doi>10.1007/BFb0017011</doi><keywords><keyword weight="0.46479">Data mining</keyword><keyword weight="0.54074">Heuristic</keyword><keyword weight="0.45447">Laplace transform</keyword><keyword weight="0.55924">Evaluation function</keyword><keyword weight="0.61931">Rule induction</keyword><keyword weight="0.62827">CN2 algorithm</keyword><keyword weight="0.40733">Mathematics</keyword><keyword weight="0.47386">Laplace operator</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>The CN2 algorithm induces an ordered list of classification rules from examples using entropy as its search heuristic. In this short paper, we describe two improvements to this algorithm. Firstly, we present the use of the Laplacian error estimate as an alternative evaluation function and secondly, we show how unordered as well as ordered rules can be generated. We experimentally demonstrate significantly improved performances resulting from these changes, thus enhancing the usefulness of CN2 as an inductive tool. Comparisons with Quinlanu0027s C4.5 are also made.</abstract></paper>