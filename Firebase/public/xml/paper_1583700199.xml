<paper id="1583700199"><title>A Practical Approach to Feature Selection</title><year>1992</year><authors><author org="Computer &amp; Information Systems Laboratory, Mitsubishi Electric Corporation, 5-1-1 Ofuna, Kamakura Kanagawa 247, Japan" id="2099432372">Kenji Kira</author><author org="Beckman Institute and Department of Computer Science, University of Illinois at Urbana-Champaign, 405 N. Mathews Avenue Urbana, IL 61801, U.S.A." id="2213964690">Larry A. Rendell</author></authors><n_citation>1849</n_citation><doc_type>Conference</doc_type><references><reference>23418094</reference><reference>64102240</reference><reference>96455041</reference><reference>190437827</reference><reference>193228784</reference><reference>1503081133</reference><reference>1527189973</reference><reference>1553142774</reference><reference>1580500061</reference><reference>1999038366</reference><reference>2004162112</reference><reference>2026605634</reference><reference>2147169507</reference></references><venue id="1180662882" type="C">International Conference on Machine Learning</venue><doi>10.1016/B978-1-55860-247-2.50037-1</doi><keywords><keyword weight="0.46779">Data mining</keyword><keyword weight="0.61219">Feature selection</keyword><keyword weight="0.4581">Computer science</keyword><keyword weight="0.5439">Concept learning</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.50254">Time complexity</keyword><keyword weight="0.44992">Empirical research</keyword><keyword weight="0.50453">Heuristic</keyword><keyword weight="0.4667">Pattern recognition</keyword><keyword weight="0.58354">Feature (computer vision)</keyword><keyword weight="0.56072">Minimum redundancy feature selection</keyword><keyword weight="0.44564">LED display</keyword><keyword weight="0.47233">Machine learning</keyword></keywords><publisher>Morgan Kaufmann Publishers Inc.</publisher><abstract>In real-world concept learning problems, the representation of data often uses many features, only a few of which may be related to the target concept. In this situation, feature selection is important both to speed up learning and to improve concept quality. A new feature selection algorithm Relief uses a statistical method and avoids heuristic search. Relief requires linear time in the number of given features and the number of training instances regardless of the target concept to be learned. Although the algorithm does not necessarily find the smallest subset of features, the size tends to be small because only statistically relevant features are selected. This paper focuses on empirical test results in two artificial domains; the LED Display domain and the Parity domain with and without noise. Comparison with other feature selection algorithms shows Reliefu0027s advantages in terms of learning time and the accuracy of the learned concept, suggesting Reliefu0027s practicality.</abstract></paper>