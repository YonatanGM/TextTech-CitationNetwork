<paper id="1850914115"><title>Active Learning of the Generalized High-Low Game</title><year>1996</year><authors><author org="UNIVERSITÄT BIELEFELD" id="2001169312">Martina Hasenjäger</author><author org="UNIVERSITÄT BIELEFELD" id="2114361001">Helge Ritter</author></authors><n_citation>5</n_citation><doc_type>Conference</doc_type><references><reference>2080021732</reference><reference>2110327402</reference></references><venue id="1158833223" type="C">International Conference on Artificial Neural Networks</venue><doi>10.1007/3-540-61510-5_86</doi><keywords><keyword weight="0.63943">Query optimization</keyword><keyword weight="0.57816">Active learning</keyword><keyword weight="0.69314">Active learning (machine learning)</keyword><keyword weight="0.45843">Computer science</keyword><keyword weight="0.58886">Sargable</keyword><keyword weight="0.0">Information gain</keyword><keyword weight="0.47498">Weight</keyword><keyword weight="0.47328">Artificial intelligence</keyword><keyword weight="0.4716">Machine learning</keyword><keyword weight="0.0">Version space</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>In this paper, we study the performance of active learning with the query algorithm Query by Committee (QBC), which selects a new query such that it approximately maximizes the expected information gain. As target functions, we introduce a generalization of the High-Low-Game, for which we derive a theoretically optimal query sequence. This allows us to compare the performance of a QBC-learner with an information-optimal active learner. Simulations show that an active learner that selects queries with QBC rapidly converges against a learner trained with theoretically optimal queries.</abstract></paper>