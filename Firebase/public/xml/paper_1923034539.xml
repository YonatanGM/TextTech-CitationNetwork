<paper id="1923034539"><title>Recognizing emotion in speech</title><year>1996</year><authors><author org="School of Computer Science Carnegie Mellon University, Pittsburgh, PA, USA" id="264739863">F. Dellaert</author><author org="" id="2072325563">T. Polzin</author><author org="" id="2061074560">A. Waibel</author></authors><n_citation>437</n_citation><doc_type>Conference</doc_type><references><reference>1993584577</reference><reference>2129113961</reference></references><venue id="2755183362" type="C">International Conference on Spoken Language Processing</venue><doi>10.1109/ICSLP.1996.608022</doi><keywords><keyword weight="0.0">Training set</keyword><keyword weight="0.42371">Spline (mathematics)</keyword><keyword weight="0.59436">Pitch contour</keyword><keyword weight="0.43378">Voting</keyword><keyword weight="0.45236">Subspace topology</keyword><keyword weight="0.42092">Computer science</keyword><keyword weight="0.48719">Smoothing spline</keyword><keyword weight="0.48056">Speech recognition</keyword><keyword weight="0.50313">Feature extraction</keyword><keyword weight="0.44939">Majority rule</keyword></keywords><publisher>INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING</publisher><abstract>The paper explores several statistical pattern recognition techniques to classify utterances according to their emotional content. The authors have recorded a corpus containing emotional speech with over a 1000 utterances from different speakers. They present a new method of extracting prosodic features from speech, based on a smoothing spline approximation of the pitch contour. To make maximal use of the limited amount of training data available, they introduce a novel pattern recognition technique: majority voting of subspace specialists. Using this technique, they obtain classification performance that is close to human performance on the task.</abstract></paper>