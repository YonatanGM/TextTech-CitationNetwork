<paper id="1550560403"><title>A Multi-agent System for Electronic Commerce including Adaptive Strategic Behaviours</title><year>1999</year><authors><author org="Universidade do Porto, NIAD&amp;R-LIACC" id="2249070831">Henrique Lopes Cardoso</author><author org="Universidade do Porto, NIAD&amp;R-LIACC" id="2714224410">Max Schaefer</author><author org="Universidade do Porto, NIAD&amp;R-LIACC" id="2146195747">Eugenio Oliveira</author></authors><n_citation>14</n_citation><doc_type>Conference</doc_type><references><reference>1537808693</reference><reference>2029459238</reference><reference>2098755476</reference><reference>2105440797</reference><reference>2121863487</reference></references><venue id="1180700458" type="C">Portuguese Conference on Artificial Intelligence</venue><doi>10.1007/3-540-48159-1_18</doi><keywords><keyword weight="0.44942">Computer science</keyword><keyword weight="0.50154">Adaptive system</keyword><keyword weight="0.57667">Software agent</keyword><keyword weight="0.62204">Multi-agent system</keyword><keyword weight="0.45389">Artificial intelligence</keyword><keyword weight="0.0">Adaptive agents</keyword><keyword weight="0.44731">Competitor analysis</keyword><keyword weight="0.48762">Negotiation</keyword><keyword weight="0.57857">Reinforcement learning</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>This work is primarily based on the use of software agents for automated negotiation. We present in this paper a test-bed for agents in an electronic marketplace, through which we simulated different scenarios allowing us to evaluate different agentsu0027 negotiation behaviours. The system follows a multi-party and multi-issue negotiation approach. We tested the system by comparing the performance of agents that use multiple tactics with ones that include learning capabilities based on a specific kind of Reinforcement Learning technique. First experiments showed that the adaptive agents tend to win deals over their competitors as their experience increases.</abstract></paper>