<paper id="1965108324"><title>A network approach to probabilistic information retrieval</title><year>1995</year><authors><author org="Queens College, City University of New York, Flushing, NY#TAB#" id="2875584499">K. L. Kwok</author></authors><n_citation>87</n_citation><doc_type>Journal</doc_type><references><reference>198085162</reference><reference>1605110775</reference><reference>1966365186</reference><reference>1987936485</reference><reference>1992054037</reference><reference>1996376230</reference><reference>2000672666</reference><reference>2003725232</reference><reference>2004942105</reference><reference>2007563768</reference><reference>2009716188</reference><reference>2012318340</reference><reference>2028747520</reference><reference>2038925774</reference><reference>2039495682</reference><reference>2043351574</reference><reference>2043909051</reference><reference>2053358180</reference><reference>2068632118</reference><reference>2078875869</reference><reference>2082729696</reference><reference>2087499664</reference><reference>2094004251</reference><reference>2102046030</reference><reference>2108521387</reference><reference>2123364985</reference><reference>2138932367</reference><reference>2144211451</reference><reference>2147152072</reference><reference>2212118560</reference></references><venue id="87067389" type="J">ACM Transactions on Information Systems</venue><doi>10.1145/203052.203067</doi><keywords><keyword weight="0.46707">Data mining</keyword><keyword weight="0.57487">Divergence-from-randomness model</keyword><keyword weight="0.59097">Query language</keyword><keyword weight="0.63997">Relevance feedback</keyword><keyword weight="0.46888">Information retrieval</keyword><keyword weight="0.68879">Query expansion</keyword><keyword weight="0.45671">Computer science</keyword><keyword weight="0.59067">Precision and recall</keyword><keyword weight="0.57898">Learning rule</keyword><keyword weight="0.60969">Ranking (information retrieval)</keyword><keyword weight="0.51935">Sequence learning</keyword></keywords><publisher>ACM</publisher><abstract>In this article we show how probabilistic information retrieval based on document components may be implemented as a feedforward (feedbackward) artificial neural network. The network supports adaptation of connection weights as well as the growing of new edges between queries and terms based on user relevance feedback data for training, and it reflects query modification and expansion in information retrieval. A learning rule is applied that can also be viewed as supporting sequential learning using a harmonic sequence learning rate. Experimental results with four standard small collections and a large Wall Street Journal collection (173,219 documents) show that performance of feedback improves substantially over no feedback, and further gains are obtained when queries are expanded with terms from the feedback documents. The effect is much more pronounced in small collections than in the large collection. Query expansion may be considered as a tool for both precision and recall enhancement. In particular, small query expansion levels of about 30 terms can achieve most of the gains at the low-recall high-precision region, while larger expansion levels continue to provide gains at the high-recall low-precision region of a precision recall curve.</abstract></paper>