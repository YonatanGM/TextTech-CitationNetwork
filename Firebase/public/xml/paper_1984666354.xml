<paper id="1984666354"><title>Random DFA's can be approximately learned from sparse uniform examples</title><year>1992</year><authors><author org="NEC Research Institute, 4 Independence Way, Princeton NJ" id="2762320514">Kevin J. Lang</author></authors><n_citation>121</n_citation><doc_type>Conference</doc_type><references><reference>2011398297</reference><reference>2018706164</reference><reference>2020284627</reference><reference>2047158580</reference><reference>2074010768</reference><reference>2142399242</reference><reference>2157526632</reference></references><venue id="1177622950" type="C">Conference on Learning Theory</venue><doi>10.1145/130385.130390</doi><keywords><keyword weight="0.0">Training set</keyword><keyword weight="0.45327">Computer science</keyword><keyword weight="0.67039">Sparse approximation</keyword><keyword weight="0.56328">Finite-state machine</keyword><keyword weight="0.47104">Theoretical computer science</keyword><keyword weight="0.58817">Approximate inference</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.42307">Adversary</keyword><keyword weight="0.4631">Machine learning</keyword><keyword weight="0.53392">Sparse matrix</keyword></keywords><publisher>ACM</publisher><abstract>Approximate inference of finite state machines from sparse labeled examples has been proved NP-hard when an adversary chooses the target machine and the training set [Ang78, KV89, PW89]. We have, however, empirically found that DFAu0027s are approximately learnable from sparse data when the target machine and training set are selected at random.</abstract></paper>