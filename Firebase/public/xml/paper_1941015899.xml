<paper id="1941015899"><title>Recognition of continuously read natural corpus</title><year>1978</year><authors><author org="IBM T.J. Watson Research, Center Yorktown Heights, NY, USA" id="2075955518">L. Bahl</author><author org="" id="2798306316">J. Baker</author><author org="" id="2798292489">P. Cohen</author><author org="" id="2019534230">F. Jelinek</author><author org="" id="2290899851">B. Lewis</author><author org="" id="2166884361">R. Mercer</author></authors><n_citation>96</n_citation><doc_type>Conference</doc_type><references><reference>2134587001</reference><reference>2157477135</reference></references><venue id="1121227772" type="C">International Conference on Acoustics, Speech, and Signal Processing</venue><doi>10.1109/ICASSP.1978.1170402</doi><keywords><keyword weight="0.57486">Perplexity</keyword><keyword weight="0.40826">Computer science</keyword><keyword weight="0.54066">Word error rate</keyword><keyword weight="0.4564">Speech recognition</keyword><keyword weight="0.5013">Natural language</keyword><keyword weight="0.45801">Natural language processing</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.41114">Decoding methods</keyword><keyword weight="0.40458">Loudspeaker</keyword><keyword weight="0.54515">Vocabulary</keyword><keyword weight="0.45117">Test set</keyword></keywords><publisher>IEEE</publisher><abstract>Preliminary results have been obtained with a system for recognizing continuously read sentences from a naturally-occurring corpus (Laser Patents), restricted to a 1000-word vocabulary. Our model of the task language has an entropy of about 4.8 bits/word and a perplexity of 21.11 words. Many new problems arise in recognition of a substantial natural corpus (compared to recognition of an artificially constrained language). Some techniques are described for treating these problems. On a test set consisting of 20 sentences having a total of 486 words, there was a word error rate of 33.1%.</abstract></paper>