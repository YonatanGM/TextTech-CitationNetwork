<paper id="1870886715"><title>Emotions in time domain synthesis</title><year>1996</year><authors><author org="Lernout &amp; Hauspie Speech Products, Ieper, Belgium" id="2983458455">B. Heuft</author><author org="" id="699072579">T. Portele</author><author org="" id="2609774868">M. Rauth</author></authors><n_citation>40</n_citation><doc_type>Conference</doc_type><references><reference>2019540503</reference><reference>2406167342</reference></references><venue id="2755183362" type="C">International Conference on Spoken Language Processing</venue><doi>10.1109/ICSLP.1996.608023</doi><keywords><keyword weight="0.45425">Time domain</keyword><keyword weight="0.56472">Speech synthesis</keyword><keyword weight="0.37638">Computer science</keyword><keyword weight="0.44878">Speech recognition</keyword><keyword weight="0.46112">Natural language</keyword><keyword weight="0.43282">Jitter</keyword><keyword weight="0.41282">Stimulus (physiology)</keyword><keyword weight="0.48812">Sawtooth wave</keyword><keyword weight="0.47615">Loudspeaker</keyword><keyword weight="0.46096">Perception</keyword></keywords><publisher>IEEE</publisher><abstract>A preliminary test exploring 4 emotions showed that conveying emotions by time domain synthesis may be possible. Therefore, a more sophisticated test was carried out in order to determine the influence of the prosodic parameters in the perception of a speakeru0027s emotional state. Six different emotional states were investigated. The stimuli of the second test were used in three different testing procedures: as natural speech, resynthesized and reduced to a sawtooth signal. The recognition rates were lower than in the preliminary test, although the differences between the recognition rates of natural and synthetic speech were comparable for both tests. The outcome of the sawtooth test showed that the amount of information about a speakeru0027s emotional state transported by F/sub 0/, energy and overall duration is rather small. However, one could determine relations between the acoustic prosodic parameters and the emotional content of speech.</abstract></paper>