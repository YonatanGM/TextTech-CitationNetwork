<paper id="1579665324"><title>Trading off simplicity and coverage in incremental concept learning</title><year>1988</year><authors><author org="Department of Information and Computer Science, University of California Irvine, CA" id="379189452">Wayne Iba</author><author org="Department of Information and Computer Science, University of California Irvine, CA" id="2239440165">James Wogulis</author><author org="Department of Information and Computer Science, University of California Irvine, CA" id="2151465254">Pat Langley</author></authors><n_citation>81</n_citation><doc_type>Conference</doc_type><references><reference>1588691067</reference><reference>1983661866</reference><reference>2009207944</reference><reference>2128420091</reference></references><venue id="1180662882" type="C">International Conference on Machine Learning</venue><doi>10.1016/B978-0-934613-64-4.50013-X</doi><keywords><keyword weight="0.56223">Hill climbing</keyword><keyword weight="0.0">Noisy data</keyword><keyword weight="0.46637">Computer science</keyword><keyword weight="0.0">Incremental learning</keyword><keyword weight="0.55805">Concept learning</keyword><keyword weight="0.51235">Evaluation function</keyword><keyword weight="0.47869">Artificial intelligence</keyword><keyword weight="0.47184">Empirical research</keyword><keyword weight="0.47829">Machine learning</keyword></keywords><publisher>Morgan Kaufmann</publisher><abstract>Abstract We present HILLARY, an incremental learning method that addresses several of the more difficult aspects of learning from examples. Specifically, HILLARY employs ‘hill climbing’ to incrementally learn disjunctive concepts from noisy data in either a relational or at tribute-value representation. In the treatment of these aspects, we have noticed an interesting tradeoff between the simplicity of candidate concept descriptions and their coverage of previously seen instances. We discuss HILLARYu0027s learning algorithm, tradeoff, and evaluation function, and we present empirical studies of the systemu0027s learning behavior on both natural and artificial domains. We show that HILLARYu0027s performance deteriorates linearly with the amount of noise, independent of the memory limitations. Also, our results show that small improvements in performance are gained at the expense of large increases in the number of disjuncts demonstrating the relevance and importance of the tradeoff. We conclude with ideas for future research.</abstract></paper>