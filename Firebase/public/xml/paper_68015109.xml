<paper id="68015109"><title>A Model for Adapting Explanations to the User‘s Likely Inferences</title><year>1997</year><authors><author org="Universität Bielefeld, LILI-Fakultät, Postfach 100 131, D-33501 Bielefeld, Germany#TAB#" id="2951812796">Helmut Horacek</author></authors><n_citation>30</n_citation><doc_type>Journal</doc_type><references><reference>18412640</reference><reference>73766171</reference><reference>93115526</reference><reference>93449816</reference><reference>144314187</reference><reference>166962601</reference><reference>219140104</reference><reference>1534011928</reference><reference>1537463254</reference><reference>1563920584</reference><reference>1594046968</reference><reference>1733954365</reference><reference>1758229847</reference><reference>1931019719</reference><reference>1943086199</reference><reference>2015240128</reference><reference>2018196704</reference><reference>2054842725</reference><reference>2057100085</reference><reference>2064823137</reference><reference>2070016268</reference><reference>2094484179</reference><reference>2102503756</reference><reference>2111309679</reference><reference>2133859229</reference><reference>2154501525</reference></references><venue id="160628929" type="J">User Modeling and User-adapted Interaction</venue><doi>10.1023/A:1008297401272</doi><keywords><keyword weight="0.52816">Natural language generation</keyword><keyword weight="0.53329">Logical consequence</keyword><keyword weight="0.58325">Rhetorical Structure Theory</keyword><keyword weight="0.464">Empirical evidence</keyword><keyword weight="0.50108">Inference</keyword><keyword weight="0.45139">Computer science</keyword><keyword weight="0.49442">Subject-matter expert</keyword><keyword weight="0.54356">Implicature</keyword><keyword weight="0.0">Planning process</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.44597">Machine learning</keyword></keywords><publisher>Kluwer Academic Publishers</publisher><abstract>In order to generate natural, high quality textual presentations in technical domains, good explanations must not only be adapted to the knowledge attributed to the intended audience, but they must also take into account the inferential capabilities of the addressees. In this paper, we present a model for anticipating contextually-motivated inferences addressees are likely to draw. This model is used to motivate choices in presenting or omitting individual pieces of information; it takes into account the addressees‘ domain expertise and expectations about logical consequences of purposefully presented information. Several kinds of empirical evidence are incorporated into a text planning process that aims at exploiting conversational implicature, so that a most suitable portion of the plan can be selected for being uttered explicitly. This way, our method adds to discourse planners based on Rhetorical Structure Theory (RST) the ability to omit easily inferable information. Thus, it overcomes one of the main shortcomings of RST. In the course of this process, rules anticipating user inferences are invoked to determine contextually justified derivability of information. In this manner, text variants can be composed on the basis of a text plan entailing annotations about the inferability of pieces of information. Moreover, pragmatically-motivated preference criteria can be used to choose among several plausible variants. The model is formulated in a reasonably domain-independent way, so that the rules expressing aspects of conversational implicature can be incorporated into typical RST-based text planners.</abstract></paper>