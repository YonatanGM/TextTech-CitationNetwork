<paper id="1973923101"><title>Improved statistical alignment models</title><year>2000</year><authors><author org="University of Technology, Aachen, Germany#TAB#" id="2233053262">Franz Josef Och</author><author org="University of Technology, Aachen, Germany#TAB#" id="2293758362">Hermann Ney</author></authors><n_citation>924</n_citation><doc_type>Conference</doc_type><references><reference>1525706028</reference><reference>1811404221</reference><reference>1979102019</reference><reference>2006969979</reference><reference>2030750105</reference><reference>2038698865</reference></references><venue id="1188739475" type="C">Meeting of the Association for Computational Linguistics</venue><doi>10.3115/1075218.1075274</doi><keywords><keyword weight="0.47081">IBM</keyword><keyword weight="0.45215">Computer science</keyword><keyword weight="0.5596">Machine translation</keyword><keyword weight="0.53554">Smoothing</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.46394">Machine learning</keyword><keyword weight="0.54288">Viterbi algorithm</keyword></keywords><publisher>Association for Computational Linguistics</publisher><abstract>In this paper, we present and compare various single-word based alignment models for statistical machine translation. We discuss the five IBM alignment models, the Hidden-Markov alignment model, smoothing techniques and various modifications. We present different methods to combine alignments. As evaluation criterion we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We show that models with a first-order dependence and a fertility model lead to significantly better results than the simple models IBM-1 or IBM-2, which are not able to go beyond zero-order dependencies.</abstract></paper>