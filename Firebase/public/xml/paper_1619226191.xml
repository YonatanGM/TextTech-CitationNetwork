<paper id="1619226191"><title>Irrelevant features and the subset selection problem</title><year>1994</year><authors><author org="Computer Science Department, Stanford University Stanford, CA" id="2140179465">George H. John</author><author org="Computer Science Department, Stanford University Stanford, CA" id="73615348">Ron Kohavi</author><author org="Computer Science Department, Stanford University Stanford, CA" id="2009573538">Karl Pfleger</author></authors><n_citation>1893</n_citation><doc_type>Conference</doc_type><references><reference>23418094</reference><reference>165133269</reference><reference>190437827</reference><reference>196871588</reference><reference>1489725718</reference><reference>1523989055</reference><reference>1533544838</reference><reference>1539166981</reference><reference>1553244859</reference><reference>1571061365</reference><reference>1583700199</reference><reference>1808644423</reference><reference>2050206309</reference><reference>2089967664</reference><reference>2098223216</reference><reference>2100775604</reference><reference>2102009083</reference><reference>2120216197</reference><reference>2129113961</reference><reference>2130759652</reference><reference>2132166479</reference><reference>2133431834</reference><reference>2148949939</reference><reference>2149706766</reference></references><venue id="1180662882" type="C">International Conference on Machine Learning</venue><doi>10.1016/B978-1-55860-335-6.50023-4</doi><keywords><keyword weight="0.45728">Pattern recognition</keyword><keyword weight="0.45044">Computer science</keyword><keyword weight="0.52312">Minimum redundancy feature selection</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.4712">ID3</keyword><keyword weight="0.46894">Machine learning</keyword></keywords><publisher>Morgan Kaufmann</publisher><abstract>We address the problem of finding a subset of features that allows a supervised induction algorithm to induce small high-accuracy concepts. We examine notions of relevance and irrelevance, and show that the definitions used in the machine learning literature do not adequately partition the features into useful categories of relevance. We present definitions for irrelevance and for two degrees of relevance. These definitions improve our understanding of the behavior of previous subset selection algorithms, and help define the subset of features that should be sought. The features selected should depend not only on the features and the target concept, but also on the induction algorithm. We describe a method for feature subset selection using cross-validation that is applicable to any induction algorithm, and discuss experiments conducted with ID3 and C4.5 on artificial and real datasets.</abstract></paper>