<paper id="1919989817"><title>Backward simulation in Bayesian networks</title><year>1994</year><authors><author org="Institute for Decision Systems Research, Los Altos, CA#TAB#" id="2099694763">Robert Fung</author><author org="Institute for Decision Systems Research, Los Altos, CA#TAB#" id="2281106656">Brendan Del Favero</author></authors><n_citation>50</n_citation><doc_type>Conference</doc_type><references><reference>1561981064</reference><reference>1580291728</reference><reference>1980452149</reference><reference>1999321705</reference><reference>1999432334</reference><reference>2037230115</reference><reference>2093976733</reference><reference>2147632348</reference><reference>2159082327</reference><reference>2173497437</reference></references><venue id="1204606053" type="C">Uncertainty in Artificial Intelligence</venue><doi>10.1016/B978-1-55860-332-5.50034-1</doi><keywords><keyword weight="0.46856">Convergence (routing)</keyword><keyword weight="0.4427">Computer science</keyword><keyword weight="0.63111">Approximate inference</keyword><keyword weight="0.6062">Bayesian network</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.70377">Bayesian statistics</keyword><keyword weight="0.45562">Machine learning</keyword></keywords><publisher>Morgan Kaufmann Publishers Inc.</publisher><abstract>Backward simulation is an approximate inference technique for Bayesian belief networks. It differs from existing simulation methods in that it starts simulation from the known evidence and works backward (i.e., contrary to the direction of the arcs). The techniqueu0027s focus on the evidence leads to improved convergence in situations where the posterior beliefs are dominated by the evidence rather than by the prior probabilities. Since this class of situations is large, the technique may make practical the application of approximate inference in Bayesian belief networks to many real-world problems.</abstract></paper>