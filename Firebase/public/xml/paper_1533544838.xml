<paper id="1533544838"><title>Efficient algorithms for minimizing cross validation error</title><year>1994</year><authors><author org="Carnegie Mellon University School of Computer Science, Pittsburgh, PA" id="2170629902">Andrew W. Moore</author><author org="6413 Howe Street, Pittsburgh, PA 15206" id="2113426514">Mary S. Lee</author></authors><n_citation>190</n_citation><doc_type>Conference</doc_type><references><reference>203646419</reference><reference>1493971443</reference><reference>1553244859</reference><reference>1571061365</reference><reference>1619226191</reference><reference>2113668251</reference><reference>2119659301</reference><reference>2147169507</reference><reference>2165962877</reference></references><venue id="1180662882" type="C">International Conference on Machine Learning</venue><doi>10.1016/B978-1-55860-335-6.50031-3</doi><keywords><keyword weight="0.476">Interval estimation</keyword><keyword weight="0.47379">Data mining</keyword><keyword weight="0.45839">Computer science</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.45032">Computation</keyword><keyword weight="0.47048">Speedup</keyword><keyword weight="0.45852">Pattern recognition</keyword><keyword weight="0.58132">Model selection</keyword><keyword weight="0.45993">Algorithm</keyword><keyword weight="0.55436">Supervised learning</keyword><keyword weight="0.46503">Robot</keyword><keyword weight="0.56448">Cross-validation</keyword><keyword weight="0.47623">Machine learning</keyword><keyword weight="0.46764">Bayesian probability</keyword></keywords><publisher>Morgan Kaufmann</publisher><abstract>Model selection is important in many areas of supervised learning. Given a dataset and a set of models for predicting with that dataset, we must choose the model which is expected to best predict future data. In some situations, such as online learning for control of robots or factories, data is cheap and human expertise costly. Cross validation can then be a highly effective method for automatic model selection. Large scale cross validation search can, however, be computationally expensive. This paper introduces new algorithms to reduce the computational burden of such searches. We show how experimental design methods can achieve this, using a technique similar to a Bayesian version of Kaelblingu0027s Interval Estimation. Several improvements are then given, including (1) the use of blocking to quickly spot near-identical models, and (2) schemata search: a new method for quickly finding families of relevant features. Experiments are presented for robot data and noisy synthetic datasets. The new algorithms speed up computation without sacrificing reliability, and in some cases are more reliable than conventional techniques.</abstract></paper>