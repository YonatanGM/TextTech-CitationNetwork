<paper id="1972508834"><title>Active learning in multimedia annotation and retrieval: A survey</title><year>2011</year><authors><author org="Microsoft Res., Asia, Beijing, China" id="2915826832">Meng Wang</author><author org="Microsoft Res., Asia, Beijing, China" id="2633183048">Xian-Sheng Hua</author></authors><n_citation>168</n_citation><doc_type>Journal</doc_type><references><reference>153490332</reference><reference>1484084878</reference><reference>1496529538</reference><reference>1515450954</reference><reference>1528361845</reference><reference>1533011499</reference><reference>1540386283</reference><reference>1544147413</reference><reference>1553262910</reference><reference>1566499617</reference><reference>1739260168</reference><reference>1845402413</reference><reference>1978633512</reference><reference>1988732650</reference><reference>2009207944</reference><reference>2024368999</reference><reference>2025363509</reference><reference>2026693436</reference><reference>2040615194</reference><reference>2048679005</reference><reference>2078528959</reference><reference>2080021732</reference><reference>2080942732</reference><reference>2083097051</reference><reference>2087544865</reference><reference>2090879738</reference><reference>2095609079</reference><reference>2096175520</reference><reference>2101498401</reference><reference>2101825085</reference><reference>2104848109</reference><reference>2107640175</reference><reference>2108745803</reference><reference>2108779687</reference><reference>2108807072</reference><reference>2109832419</reference><reference>2110119381</reference><reference>2112301781</reference><reference>2113741880</reference><reference>2116952064</reference><reference>2118168768</reference><reference>2118236796</reference><reference>2119970716</reference><reference>2122700918</reference><reference>2124244761</reference><reference>2125617179</reference><reference>2128678390</reference><reference>2129955511</reference><reference>2130660124</reference><reference>2135684690</reference><reference>2137184539</reference><reference>2138079527</reference><reference>2138334855</reference><reference>2139709458</reference><reference>2139823104</reference><reference>2141282920</reference><reference>2142126424</reference><reference>2143854982</reference><reference>2148567413</reference><reference>2151023586</reference><reference>2153356636</reference><reference>2153531403</reference><reference>2155906060</reference><reference>2161482971</reference><reference>2162977472</reference><reference>2162990951</reference><reference>2163474322</reference><reference>2164193311</reference><reference>2165966284</reference><reference>2168661348</reference><reference>2168791048</reference><reference>2426031434</reference></references><venue id="2492086750" type="J">ACM Transactions on Intelligent Systems and Technology</venue><doi>10.1145/1899412.1899414</doi><keywords><keyword weight="0.45566">Data mining</keyword><keyword weight="0.59522">Instance-based learning</keyword><keyword weight="0.61106">Active learning (machine learning)</keyword><keyword weight="0.44904">Computer science</keyword><keyword weight="0.66095">Image retrieval</keyword><keyword weight="0.57703">Unsupervised learning</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.61261">Active learning</keyword><keyword weight="0.64807">Automatic image annotation</keyword><keyword weight="0.53066">Annotation</keyword><keyword weight="0.47648">Information retrieval</keyword><keyword weight="0.46685">Machine learning</keyword><keyword weight="0.58052">Content-based image retrieval</keyword></keywords><publisher>ACM</publisher><abstract>Active learning is a machine learning technique that selects the most informative samples for labeling and uses them as training data. It has been widely explored in multimedia research community for its capability of reducing human annotation effort. In this article, we provide a survey on the efforts of leveraging active learning in multimedia annotation and retrieval. We mainly focus on two application domains: image/video annotation and content-based image retrieval. We first briefly introduce the principle of active learning and then we analyze the sample selection criteria. We categorize the existing sample selection strategies used in multimedia annotation and retrieval into five criteria: risk reduction, uncertainty, diversity, density and relevance. We then introduce several classification models used in active learning-based multimedia annotation and retrieval, including semi-supervised learning, multilabel learning and multiple instance learning. We also provide a discussion on several future trends in this research direction. In particular, we discuss cost analysis of human annotation and large-scale interactive multimedia annotation.</abstract></paper>