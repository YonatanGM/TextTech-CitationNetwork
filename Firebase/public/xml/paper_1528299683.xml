<paper id="1528299683"><title>Heterogeneous Parallel Computing Across Multidomain Clusters</title><year>2004</year><authors><author org="Emory University" id="2508990845">Peter Hwang</author><author org="Emory University" id="68912584">Dawid Kurzyniec</author><author org="Emory University" id="1976270982">Vaidy S. Sunderam</author></authors><n_citation>3</n_citation><doc_type>Journal</doc_type><references><reference>1483342079</reference><reference>1551272572</reference><reference>1969215126</reference><reference>1992178984</reference><reference>2002452469</reference><reference>2013639878</reference><reference>2023365579</reference><reference>2077783617</reference><reference>2111996486</reference><reference>2145971428</reference><reference>2146538660</reference></references><venue id="106296714" type="J">Lecture Notes in Computer Science</venue><doi>10.1007/978-3-540-30218-6_47</doi><keywords><keyword weight="0.51786">Middleware</keyword><keyword weight="0.49673">Administrative domain</keyword><keyword weight="0.47578">Parallel algorithm</keyword><keyword weight="0.44644">Computer science</keyword><keyword weight="0.45452">Parallel computing</keyword><keyword weight="0.5493">Message Passing Interface</keyword><keyword weight="0.49658">Shared resource</keyword><keyword weight="0.53992">Metacomputing</keyword><keyword weight="0.54414">Computer cluster</keyword><keyword weight="0.52293">Message passing</keyword><keyword weight="0.46546">Distributed computing</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>We propose lightweight middleware solutions that facilitate and simplify the execution of MPI programs across multidomain clusters. The system described in this paper leverages H2O, a distributed metacomputing framework, to route MPI message passing across heterogeneous aggregates located in different administrative or network domains. MPI programs instantiate a specially written H2O pluglet; messages that are destined for remote sites are intercepted and transparently forwarded to their final destinations. The software was written and tested in a simulated environment, with a focus on clusters behind firewalls. Qualitatively it was demonstrated that the proposed technique is indeed effective in enabling communication across firewalls by MPI programs. In addition, tests showed only a small drop in performance, acceptable considering the substantial added functionality of sharing new resources across different administrative domains.</abstract></paper>