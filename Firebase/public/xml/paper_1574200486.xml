<paper id="1574200486"><title>On the Effect of Instance Representation on Generalization</title><year>1991</year><authors><author org="Department of Computer and Information Science, University of Massachusetts, Amherst, MA" id="2470627036">Sharad Saxena</author></authors><n_citation>3</n_citation><doc_type>Journal</doc_type><references><reference>56903235</reference><reference>1975031941</reference><reference>2017723924</reference><reference>2031977678</reference><reference>2131882306</reference><reference>2135625884</reference><reference>2149706766</reference><reference>2163142059</reference></references><venue id="62148650" type="J">Machine Learning</venue><doi>10.1016/B978-1-55860-200-7.50043-X</doi><keywords><keyword weight="0.66662">Instance-based learning</keyword><keyword weight="0.4498">Pattern recognition</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.5047">Data compression</keyword><keyword weight="0.45613">Machine learning</keyword><keyword weight="0.42492">Mathematics</keyword><keyword weight="0.53997">Randomness</keyword></keywords><publisher>Morgan Kaufmann</publisher><abstract>This paper explains why changing the instance representation changes the ability of a class of learning algorithms to generalize from examples. The explanation is based on the correspondence between data compression and generalization. The randomness of a function with respect to a class of hypotheses is introduced as a measure of the interaction between a learning algorithm and an instance representation. Different methods of reducing randomness result in different types of representation change. Two types of representation change are identified and illustrated with examples.</abstract></paper>