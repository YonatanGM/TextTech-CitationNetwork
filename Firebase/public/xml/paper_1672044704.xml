<paper id="1672044704"><title>Computing reference classes</title><year>1986</year><authors><author org="Depts. of Computer Science and Philosophy, University of Rochester, Rochester, NY#TAB#" id="2048222250">Ronald P. Loui</author></authors><n_citation>15</n_citation><doc_type>Conference</doc_type><references><reference>13520770</reference><reference>2045833670</reference></references><venue id="1204606053" type="C">Uncertainty in Artificial Intelligence</venue><doi>10.1016/B978-0-444-70396-5.50030-3</doi><keywords><keyword weight="0.46794">Computer science</keyword><keyword weight="0.45943">Implementation</keyword><keyword weight="0.45344">Sampling (statistics)</keyword><keyword weight="0.47066">Artificial intelligence</keyword><keyword weight="0.57379">Evidential reasoning approach</keyword><keyword weight="0.46223">Machine learning</keyword></keywords><publisher>North-Holland</publisher><abstract>For any system with limited statistical knowledge, the combination of evidence and the interpretation of sampling information require the determination of the right reference class (or of an adequate one). The present note (1) discusses the use of reference classes in evidential reasoning, and (2) discusses implementations of Kyburgu0027s rules for reference classes. This paper contributes the first frank discussion of how much of Kyburgu0027s system is needed to be powerful, how much can be computed effectively, and how much is philosophical fat.</abstract></paper>