<paper id="1530964327"><title>Learning Bayesian Networks is NP-Complete</title><year>1996</year><authors><author org="University of California" id="659530374">David Maxwell Chickering</author></authors><n_citation>738</n_citation><doc_type>Conference</doc_type><references><reference>2008906462</reference><reference>2170112109</reference></references><venue id="2622962978" type="C">International Conference on Artificial Intelligence and Statistics</venue><doi>10.1007/978-1-4612-2404-4_12</doi><keywords><keyword weight="0.42244">Computer science</keyword><keyword weight="0.57827">Posterior probability</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.60082">Bayesian statistics</keyword><keyword weight="0.51136">Intelligent control</keyword><keyword weight="0.59099">Variable-order Bayesian network</keyword><keyword weight="0.45022">Algorithm</keyword><keyword weight="0.60109">Bayesian network</keyword><keyword weight="0.57575">Graphical model</keyword><keyword weight="0.42141">Statistics</keyword><keyword weight="0.44458">Machine learning</keyword><keyword weight="0.54198">Dynamic Bayesian network</keyword><keyword weight="0.55912">Bayesian probability</keyword></keywords><publisher>Springer, New York, NY</publisher><abstract>Algorithms for learning Bayesian networks from data have two components: a scoring metric and a search procedure. The scoring metric computes a score reflecting the goodness-of-fit of the structure to the data. The search procedure tries to identify network structures with high scores. Heckerman et al. (1995) introduce a Bayesian metric, called the BDe metric, that computes the relative posterior probability of a network structure given data. In this paper, we show that the search problem of identifying a Bayesian network—among those where each node has at most K parents—that has a relative posterior probability greater than a given constant is NP-complete, when the BDe metric is used.</abstract></paper>