<paper id="1964424852"><title>On the versatility of parallel sorting by regular sampling</title><year>1993</year><authors><author org="Department of Computing Science, University of Alberta, Edmonton, Alb., Canada T6G 2H1" id="2430143160">Xiaobo Li</author><author org="Department of Computing Science, University of Alberta, Edmonton, Alb., Canada T6G 2H1" id="2233643341">Paul Lu</author><author org="Department of Computing Science, University of Alberta, Edmonton, Alb., Canada T6G 2H1" id="2278512575">Jonathan Schaeffer</author><author org="Department of Computing Science, University of Alberta, Edmonton, Alb., Canada T6G 2H1" id="1224328007">John Shillington</author><author org="Department of Computing Science, University of Alberta, Edmonton, Alb., Canada T6G 2H1" id="2148725025">Pok Sze Wong</author><author org="Department of Computer Science, University of Waterloo, Waterloo, Ont., Canada N2L 3G1" id="2276442094">Hanmao Shi</author></authors><n_citation>94</n_citation><doc_type>Conference</doc_type><references><reference>1973942643</reference><reference>2051374083</reference><reference>2070771945</reference><reference>2073860632</reference><reference>2078862906</reference><reference>2092574257</reference><reference>2106166399</reference><reference>2160541517</reference><reference>2224508198</reference><reference>2293301713</reference></references><venue id="1195800536" type="C">Parallel Computing</venue><doi>10.1016/0167-8191(93)90019-H</doi><keywords><keyword weight="0.51661">Locality of reference</keyword><keyword weight="0.49466">Shared memory</keyword><keyword weight="0.47052">Oversampling</keyword><keyword weight="0.46044">Computer science</keyword><keyword weight="0.49823">Load balancing (computing)</keyword><keyword weight="0.47151">Parallel computing</keyword><keyword weight="0.46764">Workstation</keyword><keyword weight="0.55983">Sorting</keyword><keyword weight="0.46438">Theoretical computer science</keyword><keyword weight="0.46826">Hypercube</keyword><keyword weight="0.59047">MIMD</keyword></keywords><publisher>Elsevier Science Publishers B. V.</publisher><abstract>Parallel sorting algorithms have already been proposed for a variety of multiple instruction streams, multiple data streams (MIMD) architectures. These algorithms often exploit the strengths of the particular machine to achieve high performance. In many cases, however, the existing algorithms cannot achieve comparable performance on other architectures. Parallel Sorting by Regular Sampling (PSRS) is an algorithm that is suitable for a diverse range of MIMD architectures. It has good load balancing properties, modest communication needs and good memory locality of reference. If there are no duplicate keys, PSRS guarantees to balance the work among the processors within a factor of two of optimal in theory, regardless of the data value distribution, and within a few percent of optimal in practice. This paper presents new theoretical and empirical results for PSRS. The theoretical analysis of PSRS is extended to include a lower bound and a tighter upper bound on the work done by a processor. The effect of duplicate keys is addressed analytically and shown that, in practice, it is not a concern. In addition, the issues of oversampling and undersampling the data are introduced and analyzed. Empirically, PSRS has been implemented on four diverse MIMD architectures and a network of workstations. On all of the machines, for both random and application-generated data sets, the algorithm achieves good results. PSRS is not necessarily the best parallel sorting algorithm for any specific machine. But PSRS will achieve good performance on a wide spectrum of machines before any strengths of the architecture are exploited.</abstract></paper>