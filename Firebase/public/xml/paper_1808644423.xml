<paper id="1808644423"><title>Estimating attributes: Analysis and extensions of RELIEF</title><year>1994</year><authors><author org="University of Ljubljana, Slovenia;" id="1409703486">Igor Kononenko</author></authors><n_citation>1778</n_citation><doc_type>Conference</doc_type><references><reference>135311109</reference><reference>190437827</reference><reference>1583700199</reference><reference>1605844890</reference><reference>2089933214</reference><reference>2149706766</reference></references><venue id="2755314191" type="C">European conference on Machine Learning</venue><doi>10.1007/3-540-57868-4_57</doi><keywords><keyword weight="0.47976">Data mining</keyword><keyword weight="0.46323">Data set</keyword><keyword weight="0.47263">Computer science</keyword><keyword weight="0.0">Information gain</keyword><keyword weight="0.42103">Minimum redundancy feature selection</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.47825">Machine learning</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>In the context of machine learning from examples this paper deals with the problem of estimating the quality of attributes with and without dependencies among them. Kira and Rendell (1992a,b) developed an algorithm called RELIEF, which was shown to be very efficient in estimating attributes. Original RELIEF can deal with discrete and continuous attributes and is limited to only two-class problems. In this paper RELIEF is analysed and extended to deal with noisy, incomplete, and multi-class data sets. The extensions are verified on various artificial and one well known real-world problem.</abstract></paper>