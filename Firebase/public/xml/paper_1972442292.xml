<paper id="1972442292"><title>Video search reranking via information bottleneck principle</title><year>2006</year><authors><author org="Columbia University, NEW YORK, NY" id="2141240508">Winston H. Hsu</author><author org="Columbia University, NEW YORK, NY" id="2153716592">Lyndon S. Kennedy</author><author org="Columbia University, NEW YORK, NY" id="2149341496">Shih-Fu Chang</author></authors><n_citation>204</n_citation><doc_type>Conference</doc_type><references><reference>1482214997</reference><reference>1536716526</reference><reference>1578226009</reference><reference>1589050831</reference><reference>2009484134</reference><reference>2010425028</reference><reference>2031602671</reference><reference>2046624828</reference><reference>2103723258</reference><reference>2120477910</reference><reference>2130395434</reference><reference>2133455944</reference><reference>2144080413</reference><reference>2167247356</reference></references><venue id="1135237122" type="C">ACM Multimedia</venue><doi>10.1145/1180639.1180654</doi><keywords><keyword weight="0.43378">Data set</keyword><keyword weight="0.46384">Information retrieval</keyword><keyword weight="0.46296">Pattern recognition</keyword><keyword weight="0.53075">TRECVID</keyword><keyword weight="0.44002">Computer science</keyword><keyword weight="0.54874">Full text search</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.49397">Mutual information</keyword><keyword weight="0.54485">Information bottleneck method</keyword><keyword weight="0.50929">Cluster analysis</keyword><keyword weight="0.0">Visual patterns</keyword><keyword weight="0.41583">Salient</keyword></keywords><publisher>ACM</publisher><abstract>We propose a novel and generic video/image reranking algorithm, IB reranking, which reorders results from text-only searches by discovering the salient visual patterns of relevant and irrelevant shots from the approximate relevance provided by text results. The IB reranking method, based on a rigorous Information Bottleneck (IB) principle, finds the optimal clustering of images that preserves the maximal mutual information between the search relevance and the high-dimensional low-level visual features of the images in the text search results. Evaluating the approach on the TRECVID 2003-2005 data sets shows significant improvement upon the text search baseline, with relative increases in average performance of up to 23%. The method requires no image search examples from the user, but is competitive with other state-of-the-art example-based approaches. The method is also highly generic and performs comparably with sophisticated models which are highly tuned for specific classes of queries, such as named-persons. Our experimental analysis has also confirmed the proposed reranking method works well when there exist sufficient recurrent visual patterns in the search results, as often the case in multi-source news videos.</abstract></paper>