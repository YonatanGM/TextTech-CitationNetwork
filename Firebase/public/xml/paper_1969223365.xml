<paper id="1969223365"><title>A Further Comparison of Splitting Rules for Decision-Tree Induction</title><year>1992</year><authors><author org="The Turing Institute, George House, 36 North Hanover St., Glasgow, G1 2AD, U.K. Current address: Research Institute for Advanced Computer Science and Artificial Intelligence Research Branch ...#TAB#" id="2282891647">Wray Buntine</author><author org="The Turing Institute, George House, 36 North Hanover St., Glasgow, G1 2AD, U.K. TIM@TURING.AC.UK#TAB#" id="1977550913">Tim Niblett</author></authors><n_citation>209</n_citation><doc_type>Journal</doc_type><references><reference>177590838</reference><reference>1534707631</reference><reference>1559570474</reference><reference>1999011285</reference><reference>1999038366</reference><reference>2009708807</reference><reference>2128420091</reference><reference>2135479218</reference><reference>2136000097</reference><reference>2149706766</reference><reference>2150588481</reference></references><venue id="62148650" type="J">Machine Learning</venue><doi>10.1023/A:1022686419106</doi><keywords><keyword weight="0.60514">Decision tree</keyword><keyword weight="0.0">Noisy data</keyword><keyword weight="0.45792">Pattern recognition</keyword><keyword weight="0.63279">Recursive partitioning</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.46397">Machine learning</keyword><keyword weight="0.65813">Decision tree learning</keyword><keyword weight="0.42708">Mathematics</keyword></keywords><publisher>Kluwer Academic Publishers</publisher><abstract>One approach to learning classification rules from examples is to build decision trees. A review and comparison paper by Mingers (Mingers, 1989) looked at the first stage of tree building, which uses a “splitting rule” to grow trees with a greedy recursive partitioning algorithm. That paper considered a number of different measures and experimentally examined their behavior on four domains. The main conclusion was that a random splitting rule does not significantly decrease classificational accuracy. This note suggests an alternative experimental method and presents additional results on further domains. Our results indicate that random splitting leads to increased error. These results are at variance with those presented by Mingers.</abstract></paper>