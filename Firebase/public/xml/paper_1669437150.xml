<paper id="1669437150"><title>Operations for learning with graphical models</title><year>1994</year><authors><author org="RIACS &amp; NASA Ames Research Center, Moffett Field, CA#TAB#" id="2282891647">Wray L. Buntine</author></authors><n_citation>454</n_citation><doc_type>Journal</doc_type><references><reference>4326551</reference><reference>47548177</reference><reference>89983288</reference><reference>1517819558</reference><reference>1534707631</reference><reference>1565763124</reference><reference>1625504505</reference><reference>1667614912</reference><reference>1968323507</reference><reference>1989926363</reference><reference>2008906462</reference><reference>2013567125</reference><reference>2049488596</reference><reference>2111051539</reference><reference>2112514080</reference><reference>2113214579</reference><reference>2113677269</reference><reference>2114154044</reference><reference>2119394710</reference><reference>2133671888</reference><reference>2156297475</reference><reference>2159080219</reference><reference>2428981601</reference><reference>2615953416</reference><reference>2727300753</reference><reference>2912937828</reference></references><venue id="139930977" type="J">Journal of Artificial Intelligence Research</venue><doi>10.1613/jair.62</doi><keywords><keyword weight="0.5073">Graph theory</keyword><keyword weight="0.49616">Standard algorithms</keyword><keyword weight="0.51079">Expectationâ€“maximization algorithm</keyword><keyword weight="0.46623">Computer science</keyword><keyword weight="0.52749">Markov chain</keyword><keyword weight="0.47731">Directed graph</keyword><keyword weight="0.59557">Bayesian network</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.72297">Graphical model</keyword><keyword weight="0.4703">Machine learning</keyword><keyword weight="0.58871">Gibbs sampling</keyword></keywords><publisher>AI Access Foundation</publisher><abstract>This paper is a multidisciplinary review of empirical, statistical learning from a graphical model perspective. Well-known examples of graphical models include Bayesian networks, directed graphs representing a Markov chain, and undirected networks representing a Markov field. These graphical models are extended to model data analysis and empirical learning using the notation of plates. Graphical operations for simplifying and manipulating a problem are provided including decomposition, differentiation, and the manipulation of probability models from the exponential family. Two standard algorithm schemas for learning are reviewed in a graphical framework: Gibbs sampling and the expectation maximization algorithm. Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification. This includes versions of linear regression, techniques for feed-forward networks, and learning Gaussian and discrete Bayesian networks frorn data. The paper concludes by sketching some implications for data analysis and summarizing how some popular algorithms fall within the framework :[149],"main original contributions here are the decomposition techniques and the demonstration that graphical models provide a framework for understanding and developing complex learning algorithms.</abstract></paper>