<paper id="1986269798"><title>Evaluating software development by error analysis: The data from the Architecture Research Facility</title><year>1984</year><authors><author org="Naval Research Laboratory, Washington, D.C.U.S.A.#TAB#" id="2618245063">David M. Weiss</author></authors><n_citation>29</n_citation><doc_type>Journal</doc_type><references><reference>2011715836</reference><reference>2089268152</reference><reference>2089856939</reference><reference>2116844130</reference><reference>2126538733</reference><reference>2134119432</reference></references><venue id="37879656" type="J">Journal of Systems and Software</venue><doi>10.1016/0164-1212(79)90005-0</doi><keywords><keyword weight="0.52346">Data collection</keyword><keyword weight="0.46569">Software engineering</keyword><keyword weight="0.60607">Software quality analyst</keyword><keyword weight="0.46499">Computer science</keyword><keyword weight="0.57642">Package development process</keyword><keyword weight="0.51583">Error detection and correction</keyword><keyword weight="0.60171">Software development process</keyword><keyword weight="0.59896">Software construction</keyword><keyword weight="0.52705">Computer programming</keyword><keyword weight="0.60863">Software development</keyword></keywords><publisher>Elsevier Science Inc.</publisher><abstract>In software engineering, it is easy to propose techniques for improving software development but difficult to test the claims made for such techniques. This paper suggests an error analysis technique for use in gathering data concerning the effectiveness of different software development methodologies. The principal features of the error analysis technique described are the formulation of questions of interest and a data classification scheme before data collection begins, and interviews of system developers concomitant with the development process to verify the accuracy of the data. The data obtained by using this technique during the development of a medium-size software development project is presented. This project was known as the Architecture Research Facility (ARF) and took about 10 months and 192 man-weeks of effort to develop. The ARF designers used the information hiding principle to modularize the system, and interface specifications and high-level language coding specifications to express the design. Several error detection aids were designed into the system to help detect run-time errors. In addition, quality control rules were established that required review of specifications before coding, and review of code after compilation but prior to testing. A total of 143 errors was reported. Analysis of these errors showed that there were few problems caused by intermodule interfaces, that error corrections rarely required knowledge of more than one module, that most errors took less than a few hours to fix, and that the error detection aids detected more than half of the errors that were potentially detectable by them.</abstract></paper>