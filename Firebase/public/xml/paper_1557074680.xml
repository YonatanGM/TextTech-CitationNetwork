<paper id="1557074680"><title>Statistical Models for Text Segmentation</title><year>1999</year><authors><author org="School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA#TAB#" id="2625143650">Doug Beeferman</author><author org="School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA#TAB#" id="2133897374">Adam Berger</author><author org="School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA#TAB#" id="1976640904">John Lafferty</author></authors><n_citation>543</n_citation><doc_type>Journal</doc_type><references><reference>1482854515</reference><reference>1669912781</reference><reference>1730134856</reference><reference>1828401780</reference><reference>1979459060</reference><reference>1996903695</reference><reference>2061302668</reference><reference>2072223048</reference><reference>2096175520</reference><reference>2100873065</reference><reference>2107402508</reference><reference>2120804083</reference><reference>2120866163</reference><reference>2127836646</reference><reference>2134237567</reference><reference>2139042198</reference><reference>2142843952</reference><reference>2149041454</reference><reference>2160842254</reference><reference>2167055684</reference><reference>2949496004</reference></references><venue id="62148650" type="J">Machine Learning</venue><doi>10.1023/A:1007506220214</doi><keywords><keyword weight="0.49405">Decision tree</keyword><keyword weight="0.4464">Computer science</keyword><keyword weight="0.47189">Natural language processing</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.0">Quantitative assessment</keyword><keyword weight="0.52328">Language model</keyword><keyword weight="0.44849">Broadcasting</keyword><keyword weight="0.47115">Pattern recognition</keyword><keyword weight="0.5188">Precision and recall</keyword><keyword weight="0.56424">Text segmentation</keyword><keyword weight="0.51439">Statistical model</keyword><keyword weight="0.47224">Principle of maximum entropy</keyword><keyword weight="0.46811">Machine learning</keyword></keywords><publisher>Kluwer Academic Publishers</publisher><abstract>This paper introduces a new statistical approach to automatically partitioning text into coherent segments. The approach is based on a technique that incrementally builds an exponential model to extract features that are correlated with the presence of boundaries in labeled training text. The models use two classes of features: topicality features that use adaptive language models in a novel way to detect broad changes of topic, and cue-word features that detect occurrences of specific words, which may be domain-specific, that tend to be used near segment boundaries. Assessment of our approach on quantitative and qualitative grounds demonstrates its effectiveness in two very different domains, Wall Street Journal news articles and television broadcast news story transcripts. Quantitative results on these domains are presented using a new probabilistically motivated error metric, which combines precision and recall in a natural and flexible way. This metric is used to make a quantitative assessment of the relative contributions of the different feature types, as well as a comparison with decision trees and previously proposed text segmentation algorithms.</abstract></paper>