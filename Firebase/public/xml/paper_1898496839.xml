<paper id="1898496839"><title>An extensible Framework for Data Cleaning</title><year>2000</year><authors><author org="INRIA Rocquencourt#TAB#" id="2554799787">H. Galhard</author><author org="ComUE Paris-Saclay" id="2061024894">D. Florescu</author><author org="French Institute for Research in Computer Science and Automation" id="2082974086">D. Shasha</author><author org="ComUE Paris-Saclay" id="2108660490">E. Simon</author></authors><n_citation>104</n_citation><doc_type>Conference</doc_type><references><reference>4417138</reference><reference>5685153</reference><reference>53626277</reference><reference>1485956171</reference><reference>1507469828</reference><reference>1536603646</reference><reference>1569123402</reference><reference>1595677131</reference><reference>1612155886</reference><reference>1982524776</reference><reference>2005379079</reference><reference>2010595692</reference><reference>2024770506</reference><reference>2038281398</reference><reference>2060883486</reference><reference>2072647642</reference><reference>2087898817</reference><reference>2112719612</reference><reference>2142104809</reference><reference>2171197083</reference></references><venue id="1163988186" type="C">International Conference on Data Engineering</venue><doi>10.1109/ICDE.2000.839429</doi><keywords><keyword weight="0.60207">Data integration</keyword><keyword weight="0.6106">Data warehouse</keyword><keyword weight="0.49579">Query optimization</keyword><keyword weight="0.5474">SQL</keyword><keyword weight="0.52864">Hash join</keyword><keyword weight="0.47187">Data mining</keyword><keyword weight="0.4853">Query language</keyword><keyword weight="0.52184">Relational database</keyword><keyword weight="0.47807">Computer science</keyword><keyword weight="0.4733">Theoretical computer science</keyword><keyword weight="0.46604">Schema (psychology)</keyword><keyword weight="0.46676">Database</keyword></keywords><publisher>IEEE</publisher><abstract>Data integration solutions dealing with large amounts of data have been strongly required in the last few years. Besides the traditional data integration problems (e.g. schema integration, local to global schema mappings), three additional data problems have to be dealt with: (1) the absence of universal keys across different databases that is known as the object identity problem, (2) the existence of keyborad errors in the data, and (3) the presence of inconsistencies in data coming from multiple sources. Dealing with these problems is globally called the data cleaning process. In this work, we propose a framework which offers the fundamental services required by this process: data transformation, duplicate elimination and multi-table matching. These services are implemented using a set of purposely designed macro-operators. Moreover, we propose an SQL extension for specifying each of the macro-operators. One important feature of the framework is the ability of explicitly including the human interaction in the process. The main novelty of the work is that the framework permits the following performance optimizations which are tailored for data cleaning applications: mixed evaluation, neighborhood hash join, decision push-down and short-circuited computation. We measure the benefits of each.</abstract></paper>