<paper id="1481708982"><title>Wikipedia-based semantic smoothing for the language modeling approach to information retrieval</title><year>2010</year><authors><author org="Engineering S Research Center For Information Technology On Education, Huazhong Normal University, Wuhan, China#TAB#" id="2436507677">Xinhui Tu</author><author org="Engineering S Research Center For Information Technology On Education, Huazhong Normal University, Wuhan, China#TAB#" id="2627626979">Tingting He</author><author org="Birkbeck, Univ. of London#TAB#" id="2653627360">Long Chen</author><author org="Department of Computer Science and Technology, Wuhan University of Science and Technology, Wuhan, China#TAB#" id="2438063913">Jing Luo</author><author org="Engineering S Research Center For Information Technology On Education, Huazhong Normal University, Wuhan, China#TAB#" id="2557233391">Maoyuan Zhang</author></authors><n_citation>7</n_citation><doc_type>Conference</doc_type><references><reference>103965747</reference><reference>1964348731</reference><reference>1975422446</reference><reference>2062270497</reference><reference>2068905009</reference><reference>2093390569</reference><reference>2095683564</reference><reference>2100335205</reference><reference>2108937378</reference><reference>2120779048</reference><reference>2130395434</reference><reference>2136542423</reference><reference>2138861205</reference><reference>2148691410</reference><reference>2162746367</reference></references><venue id="1180513217" type="C">European Conference on Information Retrieval</venue><doi>10.1007/978-3-642-12275-0_33</doi><keywords><keyword weight="0.48518">Concept map</keyword><keyword weight="0.46571">Data mining</keyword><keyword weight="0.0">Contextual information</keyword><keyword weight="0.63628">Semantic mapping</keyword><keyword weight="0.48168">Information retrieval</keyword><keyword weight="0.4492">Expectationâ€“maximization algorithm</keyword><keyword weight="0.45506">Computer science</keyword><keyword weight="0.69664">Explicit semantic analysis</keyword><keyword weight="0.55227">Smoothing</keyword><keyword weight="0.48349">Natural language processing</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.60001">Language model</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>Semantic smoothing for the language modeling approach to information retrieval is significant and effective to improve retrieval performance. In previous methods such as the translation model, individual terms or phrases are used to do semantic mapping. These models are not very efficient when faced with ambiguous words and phrases because they are unable to incorporate contextual information. To overcome this limitation, we propose a novel Wikipedia-based semantic smoothing method that decomposes a document into a set of weighted Wikipedia concepts and then maps those unambiguous Wikipedia concepts into query terms. The mapping probabilities from each Wikipedia concept to individual terms are estimated through the EM algorithm. Document models based on Wikipedia concept mapping are then derived. The new smoothing method is evaluated on the TREC Ad Hoc Track (Disks 1, 2, and 3) collections. Experiments show significant improvements over the two-stage language model, as well as the language model with translation-based semantic smoothing.</abstract></paper>