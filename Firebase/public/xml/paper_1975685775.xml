<paper id="1975685775"><title>Topic Analysis Using a Finite Mixture Model</title><year>2000</year><authors><author org="NEC CORPORATION" id="2942432273">Hang Li</author><author org="NEC CORPORATION" id="1444602532">Kenji Yamanishi</author></authors><n_citation>2</n_citation><doc_type>Conference</doc_type><references><reference>1557074680</reference><reference>1828401780</reference><reference>2060216474</reference><reference>2062847911</reference><reference>2068782468</reference><reference>2076800308</reference><reference>2097089247</reference><reference>2107743791</reference><reference>2111705563</reference><reference>2121227244</reference><reference>2149684865</reference><reference>2161793958</reference><reference>2167055684</reference></references><venue id="1192655580" type="C">Empirical Methods in Natural Language Processing</venue><doi>10.3115/1117794.1117799</doi><keywords><keyword weight="0.0">Topic structure</keyword><keyword weight="0.44981">Computer science</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.4674">Natural language processing</keyword><keyword weight="0.51941">Statistical model</keyword><keyword weight="0.0">Topic analysis</keyword><keyword weight="0.46016">Machine learning</keyword><keyword weight="0.56006">Mixture model</keyword></keywords><publisher>Association for Computational Linguistics</publisher><abstract>We address the issue of u0027topic analysis,u0027 by which is determined a textu0027s topic structure, which indicates what topics are included in a text, and how topics change within the text. We propose a novel approach to this issue, one based on statistical modeling and learning. We represent topics by means of word clusters, and employ a finite mixture model to represent a word distribution within a text. Our experimental results indicate that our method significantly outperforms a method that combines existing techniques.</abstract></paper>