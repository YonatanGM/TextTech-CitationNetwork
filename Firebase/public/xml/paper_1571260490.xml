<paper id="1571260490"><title>An Attentional Prototype for Early Vision</title><year>1992</year><authors><author org="University of Toronto,#TAB#" id="2063955272">Sean M. Culhane</author><author org="University of Toronto,#TAB#" id="2074551997">John K. Tsotsos</author></authors><n_citation>61</n_citation><doc_type>Conference</doc_type><references><reference>206791894</reference><reference>1592377142</reference><reference>1836880760</reference><reference>2069266228</reference><reference>2129104643</reference></references><venue id="1124077590" type="C">European Conference on Computer Vision</venue><doi>10.1007/3-540-55426-2_60</doi><keywords><keyword weight="0.43247">Receptive field</keyword><keyword weight="0.45607">Computer vision</keyword><keyword weight="0.57198">Visual processing</keyword><keyword weight="0.57983">Machine vision</keyword><keyword weight="0.42118">Computer science</keyword><keyword weight="0.0">Early vision</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.47209">Hierarchy</keyword><keyword weight="0.602">Visual perception</keyword></keywords><publisher>Springer, Berlin, Heidelberg</publisher><abstract>Researchers have long argued that an attentional mechanism is required to perform many vision tasks. This paper introduces an attentional prototype for early visual processing. Our model is composed of a processing hierarchy and an attention beam that traverses the hierarchy, passing through the regions of greatest interest and inhibiting the regions that are not relevant. The type of input to the prototype is not limited to visual stimuli. Simulations using high-resolution digitized images were conducted, with image intensity and edge information as inputs to the model. The results confirm that this prototype is both robust and fast, and promises to be essential to any real-time vision system.</abstract></paper>