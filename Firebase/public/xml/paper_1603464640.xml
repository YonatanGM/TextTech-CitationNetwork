<paper id="1603464640"><title>Improving connectionist energy minimization</title><year>1995</year><authors><author org="Center for Optimization and Semantic Control, AMDOCS Inc, Washington University, St Louis, MO#TAB#" id="1266265685">Gadi Pinkas</author><author org="Department of Information, and Computer Science, University of California, Irvine, CA#TAB#" id="294129211">Rina Dechter</author></authors><n_citation>27</n_citation><doc_type>Journal</doc_type><references><reference>4326551</reference><reference>45908618</reference><reference>47368881</reference><reference>1512015032</reference><reference>1667614912</reference><reference>2029934607</reference><reference>2045466646</reference><reference>2047620565</reference><reference>2088495259</reference><reference>2151720296</reference><reference>2159080219</reference></references><venue id="139930977" type="J">Journal of Artificial Intelligence Research</venue><doi>10.1613/jair.130</doi><keywords><keyword weight="0.51587">Constraint satisfaction</keyword><keyword weight="0.4939">Asynchronous communication</keyword><keyword weight="0.46482">Mathematical optimization</keyword><keyword weight="0.45066">Exponential function</keyword><keyword weight="0.5182">Activation function</keyword><keyword weight="0.49284">Maxima and minima</keyword><keyword weight="0.52248">Network topology</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.54975">Time complexity</keyword><keyword weight="0.427">Machine learning</keyword><keyword weight="0.3928">Mathematics</keyword><keyword weight="0.50542">Energy minimization</keyword></keywords><publisher>AI Access Foundation</publisher><abstract>Symmetric networks designed for energy minimization such as Boltzman machines and Hopfield nets are frequently investigated for use in optimization, constraint satisfaction and approximation of NP-hard problems. Nevertheless, finding a global solution (i.e., a global minimum for the energy function) is not guaranteed and even a local solution may take an exponential number of steps. We propose an improvement to the standard local activation function used for such networks. The improved algorithm guarantees that a global minimum is found in linear time for tree-like subnetworks. The algorithm, called activate, is uniform and does not assume that the network is tree-like. It can identify tree-like subnetworks even in cyclic topologies (arbitrary networks) and avoid local minima along these trees. For acyclic networks, the algorithm is guaranteed to converge to a global minimumfrom any initial state of the system (self-stabilization) and remains correct under various types of schedulers. On the negative side, we show that in the presence of cycles, no uniform algorithm exists that guarantees optimality even under a sequential asynchronous scheduler. An asynchronous scheduler can activate only one unit at a time while a synchronous scheduler can activate any number of units in a single time step. In addition, no uniform algorithm exists to optimize even acyclic networks when the scheduler is synchronous. Finally, we show how the algorithm can be improved using the cycle-cutset scheme. The general algorithm, called activate-with-cutset improves over activate and has some performance guarantees that are related to the size of the networku0027s cycle-cutset.</abstract></paper>