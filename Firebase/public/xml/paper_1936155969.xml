<paper id="1936155969"><title>MULTI‚ÄêDOCUMENT SUMMARIZATION OF EVALUATIVE TEXT</title><year>2013</year><authors><author org="Department of Computer Science, University of British Columbia Vancouver British Columbia Canada" id="1132515649">Giuseppe Carenini</author><author org="Department of Computer Science University of Toronto, Toronto, Ontario, Canada#TAB#" id="2148676791">Jackie Chi Kit Cheung</author><author org="Computer Science Division University of California at Berkeley Berkeley California USA" id="2118364164">Adam Pauls</author></authors><n_citation>124</n_citation><doc_type>Conference</doc_type><references><reference>1521842739</reference><reference>1581485226</reference><reference>1969279572</reference><reference>1978078764</reference><reference>2022204871</reference><reference>2025847116</reference><reference>2032503839</reference><reference>2063998312</reference><reference>2081375810</reference><reference>2096110600</reference><reference>2112744748</reference><reference>2148374900</reference><reference>2151552691</reference><reference>2160660844</reference><reference>2163600070</reference><reference>2166010605</reference><reference>2169401582</reference></references><venue id="1120693805" type="C">Computational Intelligence</venue><doi>10.1111/j.1467-8640.2012.00417.x</doi><keywords><keyword weight="0.42476">Abstraction</keyword><keyword weight="0.46788">Web intelligence</keyword><keyword weight="0.42626">Computer science</keyword><keyword weight="0.46042">Natural language processing</keyword><keyword weight="0.42996">Decision theory</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.5514">Multi-document summarization</keyword><keyword weight="0.54864">Automatic summarization</keyword><keyword weight="0.442">World Wide Web</keyword><keyword weight="0.47636">Natural language</keyword><keyword weight="0.43334">Strengths and weaknesses</keyword><keyword weight="0.0">User studies</keyword><keyword weight="0.43772">Machine learning</keyword></keywords><publisher>John Wiley &amp; Sons, Ltd (10.1111)</publisher><abstract>In many decision-making scenarios, people can benefit from knowing what other peopleu0027s opinions are. As more and more evaluative documents are posted on the Web, summarizing these useful resources becomes a critical task for many organizations and individuals. This paper presents a framework for summarizing a corpus of evaluative documents about a single entity by a natural language summary. We propose two summarizers: an extractive summarizer and an abstractive one. As an additional contribution, we show how our abstractive summarizer can be modified to generate summaries tailored to a model of the user preferences that is solidly grounded in decision theory and can be effectively elicited from users. We have tested our framework in three user studies. In the first one, we compared the two summarizers. They performed equally well relative to each other quantitatively, while significantly outperforming a baseline standard approach to multidocument summarization. Trends in the results as well as qualitative comments from participants suggest that the summarizers have different strengths and weaknesses. After this initial user study, we realized that the diversity of opinions expressed in the corpus (i.e., its controversiality) might play a critical role in comparing abstraction versus extraction. To clearly pinpoint the role of controversiality, we ran a second user study in which we controlled for the degree of controversiality of the corpora that were summarized for the participants. The outcome of this study indicates that for evaluative text abstraction tends to be more effective than extraction, particularly when the corpus is controversial. In the third user study we assessed the effectiveness of our user tailoring strategy. The results of this experiment confirm that user tailored summaries are more informative than untailored ones.</abstract></paper>