<paper id="1623072288"><title>TEXT CHUNKING USING TRANSFORMATION-BASED LEARNING</title><year>1999</year><authors><author org="" id="2045094435">Lance A. Ramshaw</author><author org="" id="2167829816">Mitchell P. Marcus</author></authors><n_citation>895</n_citation><doc_type>Conference</doc_type><references><reference>1630692832</reference><reference>2055438451</reference><reference>2076002267</reference><reference>2099247782</reference><reference>2102924265</reference><reference>2116266212</reference><reference>2123282296</reference><reference>2134351768</reference><reference>2170381724</reference></references><venue id="1188739475" type="C">Meeting of the Association for Computational Linguistics</venue><doi>10.1007/978-94-017-2390-9_10</doi><keywords><keyword weight="0.56682">Chunking (computing)</keyword><keyword weight="0.54518">Phrase chunking</keyword><keyword weight="0.41999">Computer science</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.46027">Natural language processing</keyword><keyword weight="0.63294">Chunking (psychology)</keyword><keyword weight="0.56345">Shallow parsing</keyword><keyword weight="0.45951">Lexical rule</keyword><keyword weight="0.49418">Precision and recall</keyword><keyword weight="0.44634">Speech recognition</keyword><keyword weight="0.48881">Sentence</keyword><keyword weight="0.43736">Machine learning</keyword><keyword weight="0.47737">Encoding (memory)</keyword></keywords><publisher>Springer Netherlands</publisher><abstract>Transformation-based learning, a technique introduced by Eric Brill (1993b), has been shown to do part-of-speech tagging with fairly high accuracy. This same method can be applied at a higher level of textual interpretation for locating chunks in the tagged text, including non-recursive “baseNP” chunks. For this purpose, it is convenient to view chunking as a tagging problem by encoding the chunk structure in new tags attached to each word. In automatic tests using Treebank-derived data, this technique achieved recall and precision rates of roughly 93% for baseNP chunks (trained on 950K words) and 88% for somewhat more complex chunks that partition the sentence (trained on 200K words). Working in this new application and with larger template and training sets has also required some interesting adaptations to the transformation-based learning approach.</abstract></paper>