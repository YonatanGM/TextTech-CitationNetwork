<paper id="1517993545"><title>Learning Bayesian networks: the combination of knowledge and statistical data</title><year>1994</year><authors><author org="Microsoft Research, Redmond, WA" id="2021640924">David Heckerman</author><author org="Computer Science Department, Technion, Haifa, Israel and Microsoft Research, Redmond, WA" id="1982493283">Dan Geiger</author><author org="Microsoft Research, Redmond, WA" id="659530374">David M. Chickering</author></authors><n_citation>90</n_citation><doc_type>Conference</doc_type><references><reference>2008906462</reference></references><venue id="1204606053" type="C">Uncertainty in Artificial Intelligence</venue><doi>10.1016/B978-1-55860-332-5.50042-0</doi><keywords><keyword weight="0.46893">Computer science</keyword><keyword weight="0.0">User knowledge</keyword><keyword weight="0.50809">Equivalence (measure theory)</keyword><keyword weight="0.59849">Bayesian network</keyword><keyword weight="0.0">Artificial intelligence</keyword><keyword weight="0.48544">Machine learning</keyword><keyword weight="0.52048">Modularity</keyword><keyword weight="0.47596">Encoding (memory)</keyword></keywords><publisher>Morgan Kaufmann Publishers Inc.</publisher><abstract>We describe scoring metrics for learning Bayesian networks from a combination of user knowledge and statistical data. We identify two important properties of metrics, which we call event equivalence and parameter modularity. These properties have been mostly ignored, but when combined, greatly simplify the encoding of a useru0027s prior knowledge. In particular, a user can express his knowledge--for the most part--as a single prior Bayesian network for the domain.</abstract></paper>